{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTlmjXExP75I"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 4. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kH11bAAV2SoV"
   },
   "source": [
    "### Общая информация\n",
    "Дата выдачи: 16.11.2024\n",
    "\n",
    "Мягкий дедлайн: 28.11.2024\n",
    "\n",
    "Жесткий дедлайн: 02.12.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWjJuhqS3Ucc"
   },
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- ознакомитесь с тем, что происходит \"внутри\" метода опорных векторов и логистической регрессии\n",
    "- познакомитесь с калибровкой вероятности\n",
    "- изучите методы трансформации переменных и методы отбора признаков\n",
    "- попробуете оценить экономический эффект модели\n",
    "\n",
    "----\n",
    "\n",
    "#### Самостоятельная оценка результатов\n",
    "\n",
    "Для удобства проверки, исходя из набора решенных задач, посчитайте свою максимальную оценку.\n",
    "\n",
    "**Оценка**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Or0r6z5v1Mmt"
   },
   "source": [
    "### Оценивание и штрафы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CecLXG_w3zs0"
   },
   "source": [
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMwMhTpA1MwR"
   },
   "source": [
    "### Формат сдачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5qs8FC_35h7"
   },
   "source": [
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-04-linclass-__Username__.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-04-linclass-__IvanovIvan__.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGWDDNDyP75O"
   },
   "source": [
    "# Часть 1. SVM, LR и калибровка вероятностей (2 балла + 0.5 бонус)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyqoX1BNP75N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "# pl.Config().set_tbl_rows(100)\n",
    "# pl.Config().set_tbl_cols(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvhLtt4OP75Q"
   },
   "source": [
    "#### __Задание 1.1  Сравнение методов__ (0.5 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZw2aOq9P75O"
   },
   "source": [
    "Сгенерируем синтетические данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqkczFrQP75P"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# фиксируем random_state для воспроизводимости результатов\n",
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdPx-lQbtaRe"
   },
   "source": [
    "__Случайный классификатор__\n",
    "\n",
    "Для начала зададим самую простую модель, которая на каждом объекте выдаёт случайный ответ. По тестовой выборке вычислим AUC-ROC, AUC-PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gcSglAOjVn-",
    "outputId": "c593c237-1319-4b1d-dbdd-5877aa42cfb1"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "random_classifier = DummyClassifier(strategy='uniform', random_state=42).fit(X_train, y_train)\n",
    "y_random = random_classifier.predict_proba(X_test)[:,1]\n",
    "y_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUhBXPre7jNi"
   },
   "source": [
    "**Вопрос:** решаем задачу бинарной классификации, но y\\_random содержит какие-то дробные числа, а не 0/1. Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpIDxyuHH1bt"
   },
   "source": [
    "**Ответ**: предсказываем вероятности вместо бинарного таргета 0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnmZFwEYDVqx"
   },
   "source": [
    "*Ниже приведен **пример** работы* со встроенными функциями `sklearn` для отрисовки ROC и PR кривых, сохранения метрик. Пайплайн можно изменять как вам удобно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNJLhNj7DkLx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depict_pr_roc(y_true, y_pred, classifier_name='Some Classifier', ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "    print(classifier_name, 'metrics')\n",
    "    PrecisionRecallDisplay.from_predictions(y_true, y_pred, ax=ax[0], name=classifier_name)\n",
    "    print('AUC-PR: %.4f' % average_precision_score(y_true, y_pred))\n",
    "    ax[0].set_title(\"PRC\")\n",
    "    ax[0].set_ylim(0, 1.1)\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_true, y_pred, ax=ax[1], name=classifier_name)\n",
    "    print('AUC-ROC: %.4f' % roc_auc_score(y_true, y_pred))\n",
    "    ax[1].set_title(\"ROC\")\n",
    "    ax[1].set_ylim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "depict_pr_roc(y_test, y_random, 'Random Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "pSugCdAAEF2z",
    "outputId": "3c3cd961-bee5-4ca5-b607-6c51fc5e1b03"
   },
   "outputs": [],
   "source": [
    "# dataframe для сравнения\n",
    "# методов классификации по метрикам\n",
    "df_metrics = pd.DataFrame(\n",
    "    columns=['auc_pr', 'roc_auc_score', 'reg_const']\n",
    ")\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_random)\n",
    "# добавление очередной строки с характеристиками метода\n",
    "df_metrics.loc['Random Classifier'] = [\n",
    "      average_precision_score(y_test, y_random),\n",
    "      roc_auc_score(y_test, y_random),\n",
    "      0,\n",
    "]\n",
    "\n",
    "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IwDobmQtW2P"
   },
   "source": [
    "__Support Vector Machine (Linear Kernel)__\n",
    "\n",
    "Обучите метод опорных векторов.\n",
    "\n",
    "Подберите параметр регуляризации `C` с точки зрения AUC-PR (можете воспользоваться кросс-валидацией или отделить валидационную выборку от обучающей).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyjF-qc3P75Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "linear_svc = LinearSVC(C=1.0,\n",
    "                       penalty=\"l2\",\n",
    "                       tol=0.0001,\n",
    "                       random_state=42,\n",
    "                       max_iter=1000)\n",
    "\n",
    "params_linear_svc = {\n",
    "    'C': np.logspace(-9, 4, 20),\n",
    "    'tol': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "}\n",
    "\n",
    "random_search_svc = RandomizedSearchCV(\n",
    "    estimator=linear_svc,\n",
    "    param_distributions=params_linear_svc,\n",
    "    cv=5,\n",
    "    n_iter=60,\n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search_svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {random_search_svc.best_params_}')\n",
    "\n",
    "# Best parameters: {'tol': 0.001, 'C': np.float64(6.158482110660267e-05)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fapa63xlP75R"
   },
   "source": [
    "  На тестовой части:\n",
    "  - постройте ROC и PR кривые,\n",
    "  - посчитайте AUC-ROC, AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# LinearSVC doesn't output probabilities directly, so we calibrate it\n",
    "calibrated_svc = CalibratedClassifierCV(random_search_svc.best_estimator_, cv=5)\n",
    "calibrated_svc.fit(X_train, y_train)\n",
    "\n",
    "# Get probability predictions for test set\n",
    "y_svc_proba = calibrated_svc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot ROC and PR curves\n",
    "depict_pr_roc(y_test, y_svc_proba, 'Linear SVC (Calibrated)')\n",
    "\n",
    "# Update metrics dataframe\n",
    "df_metrics.loc['Linear SVC'] = [\n",
    "    average_precision_score(y_test, y_svc_proba),\n",
    "    roc_auc_score(y_test, y_svc_proba),\n",
    "    random_search_svc.best_params_['C'],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTvgDyaFhkYz"
   },
   "source": [
    "Проанализируйте, как себя ведут обе кривые:\n",
    "- Что происходит при увеличении порога? Как бы вы это проинтерпретировали?\n",
    "- Монотонные ли кривые? Как вы это объясните?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ:\n",
    "\n",
    "-ROC всегда монотонна т.к. TRP and FPR при уменьшении порога будут монотонно расти (знаменатель постоянный у обеих), но TP и FP всегда увеличивается \n",
    "\n",
    "-Критическое различие: знаменатель precision  меняется при изменении порога"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln5VaZE_P75S"
   },
   "source": [
    "__Logistic Regression__\n",
    "\n",
    "\n",
    "Аналогичное задание для логистической регрессии с L2 регуляризатором:\n",
    "\n",
    "\n",
    "*   подберите гиперпараметр C, используя метрику AUC-PR\n",
    "*   нарисуйте ROC, PR кривые для тестовой части\n",
    "*   выведите метрики для тестовых данных и сравните их с результатами случайного классификатора\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1TlamoBP75S"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "                            C=1.0,\n",
    "                            penalty=\"l2\",\n",
    "                            tol=0.0001,\n",
    "                            random_state=42,\n",
    "                            max_iter=1000\n",
    ")\n",
    "\n",
    "params_log_reg = {\n",
    "    'C': np.logspace(-9, 4, 20),\n",
    "    'tol': np.logspace(-8, -2, 10)\n",
    "}\n",
    "\n",
    "random_search_log_reg = RandomizedSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_distributions=params_log_reg,\n",
    "    cv=5,\n",
    "    n_iter=60,\n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search_log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {random_search_log_reg.best_params_}')\n",
    "\n",
    "# Best parameters: {'tol': np.float64(2.154822e-07), 'C': np.float64(0.00029763)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions for test set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_log_reg_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot ROC and PR curves\n",
    "depict_pr_roc(y_test, y_log_reg_proba, 'Logistic Regression + L2')\n",
    "\n",
    "# Update metrics dataframe\n",
    "df_metrics.loc['Logistic Regression + L2'] = [\n",
    "    average_precision_score(y_test, y_log_reg_proba),\n",
    "    roc_auc_score(y_test, y_log_reg_proba),\n",
    "    random_search_log_reg.best_params_['C'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnj5PG1Rm5qX"
   },
   "source": [
    "Нарисуйте ROC, PR кривые для тестовой части для всех 3 классификаторов на одном графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3BaXTRBnAwK"
   },
   "outputs": [],
   "source": [
    "fig, (ax_pr, ax_roc) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Random Classifier\n",
    "print('Random Classifier metrics')\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_random, ax=ax_pr, name='Random Classifier')\n",
    "print('AUC-PR: %.4f' % average_precision_score(y_test, y_random))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_random, ax=ax_roc, name='Random Classifier')\n",
    "print('AUC-ROC: %.4f' % roc_auc_score(y_test, y_random))\n",
    "\n",
    "# Linear SVC (Calibrated)\n",
    "print('\\nLinear SVC (Calibrated) metrics')\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_svc_proba, ax=ax_pr, name='Linear SVC (Calibrated)')\n",
    "print('AUC-PR: %.4f' % average_precision_score(y_test, y_svc_proba))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_svc_proba, ax=ax_roc, name='Linear SVC (Calibrated)')\n",
    "print('AUC-ROC: %.4f' % roc_auc_score(y_test, y_svc_proba))\n",
    "\n",
    "# Logistic Regression\n",
    "print('\\nLogistic Regression + L2 metrics')\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_log_reg_proba, ax=ax_pr, name='Logistic Regression + L2')\n",
    "print('AUC-PR: %.4f' % average_precision_score(y_test, y_log_reg_proba))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_log_reg_proba, ax=ax_roc, name='Logistic Regression + L2')\n",
    "print('AUC-ROC: %.4f' % roc_auc_score(y_test, y_log_reg_proba))\n",
    "\n",
    "ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "ax_pr.set_ylim(0, 1.1)\n",
    "ax_roc.set_title(\"ROC Curve\")\n",
    "ax_roc.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khlorKXtr1Sy"
   },
   "source": [
    "**Вопрос:** Сравните результаты LR и SVM с точки зрения всех вычисленных критериев качества, объясните различия (если они есть).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un_w7BMZIAf2"
   },
   "source": [
    "**Ответ:** # отличий почти нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvWzOe4wP75T"
   },
   "source": [
    "#### __Задание 1.2. Визуализация в подходах SVM, LR__ (0.5 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWS1NfYwBbQ_"
   },
   "source": [
    "В названии метода опорных векторов присутствуют некоторые \"опорные векторы\". По сути, это объекты из обучающей выборки, которые задали положение разделяющей гиперплоскости.\n",
    "\n",
    "* Сгенерируйте синтетические данные с помощью `make_classification` __с 2 признаками__, обучите на нём метод опорных векторов. Не забудьте зафиксировать seed для воспроизводимости\n",
    "\n",
    "* Визуализируйте разделяющую прямую, все объекты и выделите опорные векторы. Ниже есть шаблоны, можете воспользоваться ими, либо написать своё"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIS-aGxi-Nr0"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=2, n_informative=2, n_redundant=0, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "linear_svc = SVC(kernel='linear', C=1.0, tol=0.00001, random_state=42, max_iter=1000)\n",
    "\n",
    "params_linear_svc = {\n",
    "    'C': np.logspace(-9, 4, 20),\n",
    "}\n",
    "\n",
    "random_search_svc = RandomizedSearchCV(\n",
    "    estimator=linear_svc,\n",
    "    param_distributions=params_linear_svc,\n",
    "    cv=5,\n",
    "    n_iter=60,\n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_search_svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {random_search_svc.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_linear_svc = SVC(kernel='linear', **random_search_svc.best_params_, random_state=42)\n",
    "\n",
    "best_linear_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_linear_svc.predict(X_test)\n",
    "\n",
    "df = pd.concat([pd.DataFrame(X_test, columns=['x1', 'x2']), pd.DataFrame(y_pred, columns=['y_pred'])], axis=1)\n",
    "\n",
    "print(list(best_linear_svc.coef_[0]))\n",
    "print(best_linear_svc.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = best_linear_svc.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = best_linear_svc.coef_[0]\n",
    "b = best_linear_svc.intercept_[0]\n",
    "\n",
    "# Диапазон для оси x\n",
    "xx = np.linspace(-5, 6, 100)\n",
    "yy = -(w1 * xx + b) / w2\n",
    "\n",
    "y_0 = df[df['y_pred'] == 0]\n",
    "y_1 = df[df['y_pred'] == 1]\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.plot(xx, yy, color='green', linewidth=2, label='Гиперплоскость')\n",
    "\n",
    "# Маржины (границы отступа): w1*x1 + w2*x2 + b = ±1\n",
    "yy_margin_plus = -(w1 * xx + b + 1) / w2\n",
    "yy_margin_minus = -(w1 * xx + b - 1) / w2\n",
    "\n",
    "plt.plot(xx, yy_margin_plus, 'r--', linewidth=2, label='Верхний margin')\n",
    "plt.plot(xx, yy_margin_minus, 'r--', linewidth=2, label='Нижний margin')\n",
    "\n",
    "plt.scatter(y_0['x1'], y_0['x2'], c='red', label='Class 0', alpha=0.7)\n",
    "plt.scatter(y_1['x1'], y_1['x2'], c='blue', label='Class 1', alpha=0.7)\n",
    "\n",
    "# НАСТОЯЩИЕ support vectors из модели LinearSVC\n",
    "# LinearSVC не предоставляет .support_vectors_ напрямую, поэтому извлекаем их\n",
    "decision_vals = best_linear_svc.decision_function(df[['x1', 'x2']])\n",
    "norm_w = np.linalg.norm([w1, w2])\n",
    "\n",
    "# Точные опорные векторы: |decision_function(x)| / ||w|| <= 1 + epsilon\n",
    "distances = np.abs(decision_vals) / norm_w\n",
    "sv_mask_true = np.abs(decision_vals) <= 1 + 1e-4  # Точные SV (|w*x + b| <= 1)\n",
    "\n",
    "# Разделяем по классам настоящие SV\n",
    "df_sv_true = df[sv_mask_true].copy()\n",
    "sv_class_0_true = df_sv_true[df_sv_true['y_pred'] == 0]\n",
    "sv_class_1_true = df_sv_true[df_sv_true['y_pred'] == 1]\n",
    "\n",
    "print(f\"True SV Class 0: {len(sv_class_0_true)}\")\n",
    "print(f\"True SV Class 1: {len(sv_class_1_true)}\")\n",
    "\n",
    "# ✅ НАСТОЯЩИЕ ОПОРНЫЕ ВЕКТОРЫ - БОЛЬШИЕ ЗВЁЗДЫ\n",
    "plt.scatter(sv_class_0_true['x1'], sv_class_0_true['x2'], \n",
    "           c='gold', s=400, marker='+', \n",
    "           edgecolors='black', linewidth=3,\n",
    "           label=f'TRUE SV Class 0 (n={len(sv_class_0_true)})', zorder=10)\n",
    "\n",
    "plt.scatter(sv_class_1_true['x1'], sv_class_1_true['x2'], \n",
    "           c='limegreen', s=400, marker='+', \n",
    "           edgecolors='black', linewidth=3,\n",
    "           label=f'TRUE SV Class 1 (n={len(sv_class_1_true)})', zorder=10)\n",
    "\n",
    "# ПСЕВДО-опорные векторы (близкие к маржину) - меньшие звёздочки для сравнения\n",
    "pseudo_sv_mask = (0.95 < distances) & (distances <= 1.1)\n",
    "df_pseudo_sv = df[pseudo_sv_mask].copy()\n",
    "pseudo_sv_0 = df_pseudo_sv[df_pseudo_sv['y_pred'] == 0]\n",
    "pseudo_sv_1 = df_pseudo_sv[df_pseudo_sv['y_pred'] == 1]\n",
    "\n",
    "plt.scatter(pseudo_sv_0['x1'], pseudo_sv_0['x2'], \n",
    "           c='darkred', s=150, marker='*', \n",
    "           edgecolors='white', linewidth=1.5,\n",
    "           label=f'Pseudo-SV Class 0 (n={len(pseudo_sv_0)})', alpha=0.8)\n",
    "\n",
    "plt.scatter(pseudo_sv_1['x1'], pseudo_sv_1['x2'], \n",
    "           c='darkblue', s=150, marker='*', \n",
    "           edgecolors='white', linewidth=1.5,\n",
    "           label=f'Pseudo-SV Class 1 (n={len(pseudo_sv_1)})', alpha=0.8)\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Проверка support_vectors_ (если доступно)\n",
    "print(\"best_linear_svc.support_vectors_:\", best_linear_svc.support_vectors_ if hasattr(best_linear_svc, 'support_vectors_') else \"Not available\")\n",
    "print(\"Количество SV по классам:\", len(sv_class_0_true), len(sv_class_1_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(X_train[:,0].min(), X_train[:,0].max(), 30)\n",
    "yy = np.linspace(X_train[:,1].min(), X_train[:,1].max(), 30)\n",
    "YY, XX = np.meshgrid(yy, xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "9jA3GbO9-wcU",
    "outputId": "bfe76c4d-7958-470d-bbb2-87c779d3fda0"
   },
   "outputs": [],
   "source": [
    "def plot_svm_2D(X, y, model,  plot_support=True):\n",
    "\n",
    "    # создали сетку\n",
    "    xx = np.linspace(X[:,0].min(), X[:,0].max(), 30)\n",
    "    yy = np.linspace(X[:,1].min(), X[:,1].max(), 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "    # Ответы модели для сетки для отрисовки разделяющей прямой\n",
    "    Z = # your code here\n",
    "\n",
    "    plt.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "    # Отрисовали выборку\n",
    "    plt.scatter(\n",
    "        # your code here\n",
    "    )\n",
    "\n",
    "    # Отрисовали опорные векторы\n",
    "    if plot_support:\n",
    "        plt.scatter(\n",
    "            # your code here\n",
    "            label='support vectors',\n",
    "            s=100,\n",
    "            linewidth=1,\n",
    "            edgecolor=\"blue\",\n",
    "            facecolors='none'\n",
    "        )\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_svm_2D(X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdMs4iQAIYpu"
   },
   "source": [
    "**Вопрос:** какие объекты выделяются как \"опорные\"?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dplr4chfIXnm"
   },
   "source": [
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfpVN70PP75U"
   },
   "source": [
    "В отличие от метода опорных векторов, логистическая регрессия не пытается построить разделяющую гиперплоскость с максимальным отступом, а приближает в каждой точке пространства объектов вероятность положительных ответов $p(y=+1|x)$. Попробуйте нарисовать это распределение на плоскости, не забудьте отметить на ней все объекты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "k5D2jq87f3MC",
    "outputId": "5a04f790-e90b-4f08-d25b-dd2f553d9d8d"
   },
   "outputs": [],
   "source": [
    "def plot_logreg_2D(X, y, model):\n",
    "\n",
    "    # создали сетку\n",
    "    xx = np.linspace(X[:,0].min(), X[:,0].max(), 100)\n",
    "    yy = np.linspace(X[:,1].min(), X[:,1].max(), 100)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "    # Ответы модели для сетки для отрисовки распределения\n",
    "    Z = # your code here\n",
    "    Z = Z.reshape((xx.shape[0], -1)).T\n",
    "\n",
    "    image = plt.imshow(\n",
    "        Z,\n",
    "        interpolation='nearest',\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        cmap=plt.cm.PuOr_r\n",
    "    )\n",
    "\n",
    "    #Отрисовали выборку\n",
    "    plt.scatter(\n",
    "        # your code here\n",
    "        cmap=plt.cm.Paired\n",
    "    )\n",
    "\n",
    "    plt.colorbar(image)\n",
    "\n",
    "plot_logreg_2D(X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ-Um7-6JnAp"
   },
   "source": [
    "**Вопрос:** Как на картинке визуализирована область, где модель не уверена ($p(y=+1|x) = 0.5$)? Как это обосновать теоритечески?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAAF0HiaIh9Z"
   },
   "source": [
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VbJR0e3P75U"
   },
   "source": [
    "#### __Задание 2. Калибровка вероятностей__ (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8taLYSgBd9u"
   },
   "source": [
    "Перейдём к оценке качества выдаваемых алгоритмами вероятностей. Начнём с калибровочных кривых.\n",
    "\n",
    "Допустим, алгоритм возвращает некоторые числа от нуля до единицы. Хорошо ли они оценивают вероятность?\n",
    "\n",
    "Хорошо откалиброванный  классификатор должен выдавать значения так, чтобы среди образцов, для которых он дал значение, близкое к $\\alpha$, примерно $\\alpha * 100 \\%$ фактически принадлежали к положительному классу. (Например, если классификатор выдает 0.3 для некоторых, то 30% из них должны принадлежать классу 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRBGtMArIxMc"
   },
   "source": [
    "Для построения калибровочной криовой используем следующий алгоритм:\n",
    "\n",
    "Разобьем отрезок $[0, 1]$ на несколько маленьких отрезков одинаковой длины.\n",
    "\n",
    "Рассмотрим $i$-й отрезок с границами $[a_i, b_i]$ и предсказания $p_1, p_2, \\dots, p_k$, которые попали в него. Пусть им соответствуют истинные ответы $y_1, y_2, \\dots, y_k$. Если алгоритм выдает корректные вероятности, то среди этих истинных ответов должно быть примерно $(a_i + b_i) / 2$ единиц. Иными словами, если нарисовать кривую, у которой по оси X отложены центры отрезков, а по оси Y — доли единичных ответов этих в отрезках, то она должна оказаться диагональной.\n",
    "\n",
    "Ниже приведена функция, которая должна рисовать такие кривые. В ней допущено две ошибки — найдите и исправьте их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R75uefZuP75V"
   },
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_test, preds):\n",
    "    bin_middle_points = []\n",
    "    bin_real_ratios = []\n",
    "    n_bins = 10\n",
    "    for i in range(n_bins):\n",
    "        l = 1.0 / n_bins * i\n",
    "        r = 1.0 / n_bins * (i + 1)\n",
    "        bin_middle_points.append((l - r) / 2)\n",
    "        bin_real_ratios.append(np.min(y_test[(preds >= l) & (preds < r)] == 1))\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(bin_middle_points, bin_real_ratios)\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R13YCkxMO_R4"
   },
   "source": [
    "Сгенерируйте синтетические данные аналогично использованным в самом первом задании. Постройте калибровочные кривые на тестовой части для логистической регрессии и метода опорных векторов (не забудьте перевести его предсказания в $[0;1]$).\n",
    "\n",
    "Отрисуйте калибровочную кривую идеально откалиброванной модели (диагональ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk6pz90lQYST"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t15IAX7GPJjF"
   },
   "source": [
    "**Вопрос**: хорошо ли откалиброваны кривые для SVM, логистической регрессии? Подумайте, как это следует из вида кривой\n",
    "\n",
    "**Ответ:** # your answer here\n",
    "\n",
    "Из формальных способов в этом убедиться есть знакомый вам LogLoss, который напрямую оценивает вероятности,\n",
    "$$\\text{LogLoss} = -\\frac{1}{N}\\sum_{i} \\sum_{k \\in {0. 1}}\\log p_k[y_i = k]$$\n",
    "а так же BrierScore, который подсчитывает отклонение между получившейся вероятностью и реальным значением таргета.\n",
    "$$\\text{BrierScore} = \\frac{1}{N}\\sum_{i} (p_i - y_i)^2$$\n",
    "Посмотрите на них тоже и сделайте вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ8d-pl26rQU"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgANQZyhPHIX"
   },
   "source": [
    "Изучите распределение ответов классификаторов при помощи гистограмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAP1X3NObCXp"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.histplot(y_svc_proba, bins=50, kde=True, ax=axes[0], color='blue', alpha=0.7)\n",
    "axes[0].set_title('SVM Predicted Probabilities')\n",
    "axes[0].set_xlabel('Probability')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(y_log_reg_proba, bins=50, kde=True, ax=axes[1], color='green', alpha=0.7)\n",
    "axes[1].set_title('Logistic Regression Predicted Probabilities')\n",
    "axes[1].set_xlabel('Probability')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(y_random, bins=50, kde=True, ax=axes[2], color='red', alpha=0.7)\n",
    "axes[2].set_title('Random Classifier Predicted Probabilities')\n",
    "axes[2].set_xlabel('Probability')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7ga-L4CPK_O"
   },
   "source": [
    "**Вопрос:** Чем они различаются? Чем вы можете объяснить это?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOmrLYqdPP_0"
   },
   "source": [
    "**Ответ:** \\n\\nSVM показывает бимодальное распределение с пиками вблизи 0 и 1 - модель уверена в своих предсказаниях, разделяя классы чётко.\\n\\nLogistic Regression имеет более плавное унимодальное распределение, сосредоточенное вокруг 0.5 - модель менее уверена, выдаёт предсказания ближе к порогу.\\n\\nRandom Classifier показывает равномерное распределение в диапазоне [0, 1] - случайные предсказания без уверенности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9-6ClfaP75W"
   },
   "source": [
    "Воспользуйтесь `CalibratedClassifierCV` из `sklearn` для калибровки вероятностей метода опорных векторов на обучении и постройте с его помощью  предсказания для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RR3pVlSNP75W"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnwOFuW6XyPc"
   },
   "source": [
    "**Вопрос:** Улучшились ли калибровочная кривая и качество калибровки?\n",
    "\n",
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2dpbXgoP75X"
   },
   "source": [
    "##### __Бонус: Авторское решение__ (0.5 балла)\n",
    "\n",
    "Реализуйте свою функцию для калибровки вероятностей, используя любой из известных подходов. Кратко опишите ваш подход и продемонстрируйте результаты. Ключевые слова для вдохновения: `Platt`, `Isotonic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8mtQgBJP75X"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaOVU4vJP75X"
   },
   "source": [
    "# Часть 2. Обработка категориальных переменных (4 балла + 1.5 бонус)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KQ9ywUEP75X"
   },
   "source": [
    "Как мы знаем, перекодировать категориальную переменную в список чисел (к примеру 1, 2, 3, ..., n) плохо, поскольку это бы задало на множестве ее значений некоторый порядок, не имеющий смысла.\n",
    "\n",
    "В этой части мы рассмотрим два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPsScraBP75Y"
   },
   "source": [
    "#### __Подготовка данных__\n",
    "\n",
    "*(бесценный шаг)*\n",
    "\n",
    "Разберем датасет [покупок велосипедов](https://www.kaggle.com/datasets/heeraldedhia/bike-buyers/): даны признаки покупателя, требуется предсказать, купит ли он/она велосипед\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPuDzNoCo2nk"
   },
   "source": [
    "Замените пропуски в категориальных переменных на новую категорию (`'undefined'`)\n",
    "\n",
    "Разделите признаки на 2 таблицы: категориальные и числовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MTr7gi1PMqv",
    "outputId": "ac75b395-3705-4a43-f024-b793d0e48c80"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"heeraldedhia/bike-buyers\") +  \"/bike_buyers.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Purchased Bike'].map({'Yes': 1, 'No': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df[cat_cols].copy()\n",
    "df_num = df[num_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.drop(columns=['Purchased Bike'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.fillna('undefined', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGWlojJwOEjL"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_cat,\n",
    "    target,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ch0M2v8Akirw"
   },
   "source": [
    "В начале поработаем только с категориальными признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5LjHkuCP75Z"
   },
   "source": [
    "#### __Задание 3. OrdinalEncoder__  (0.5 балла)\n",
    "\n",
    "Закодируйте категориальные признаки с помощью `OrdinalEncoder`. Посчитайте качество (в этом задании будем работать c __`AUC-PR`__) при применении логистической регрессии. Замерьте время, потребовавшееся на обучение модели, с учетом кодирования признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Encoder', 'AUC_PR', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "def eval_encoder(encoder, encoder_name, X_train_in, X_test_in, y_train_in=None):\n",
    "    start = time.time()\n",
    "    \n",
    "    if y_train_in is None:\n",
    "        X_train_enc = encoder.fit_transform(X_train_in)\n",
    "    else:\n",
    "        X_train_enc = encoder.fit_transform(X_train_in, y_train_in)\n",
    "    X_test_enc = encoder.transform(X_test_in)\n",
    "    \n",
    "    log_reg = LogisticRegression(\n",
    "        C=1.0,\n",
    "        penalty=\"l2\",\n",
    "        tol=0.0001,\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    params_log_reg = {\n",
    "        'C': np.logspace(-9, 4, 20),\n",
    "        'tol': np.logspace(-8, -2, 10)\n",
    "    }\n",
    "    kfold = KFold(5, random_state=42, shuffle=True)\n",
    "\n",
    "    random_search_log_reg = RandomizedSearchCV(\n",
    "        estimator=log_reg,\n",
    "        param_distributions=params_log_reg,\n",
    "        cv=kfold,\n",
    "        n_iter=60,\n",
    "        scoring='average_precision',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0  # Изменено с 1 на 0 для меньшего вывода\n",
    "    )\n",
    "\n",
    "    random_search_log_reg.fit(X_train_enc, y_train)\n",
    "    \n",
    "    # Используем best_estimator_ для предсказаний\n",
    "    y_pred_proba = random_search_log_reg.best_estimator_.predict_proba(X_test_enc)[:, 1]\n",
    "    \n",
    "    auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    end = time.time()\n",
    "    sum_time = round(end - start, 6)\n",
    "    \n",
    "    # Add results to Data Frame\n",
    "    global results\n",
    "    new_row = pd.DataFrame({\n",
    "        'Encoder': [encoder_name], \n",
    "        'AUC_PR': [auc_pr], \n",
    "        'Time': [sum_time]\n",
    "    })\n",
    "    \n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "    \n",
    "    print(f\"{encoder_name}: AUC-PR = {auc_pr:.4f}, Time = {sum_time:.4f}s\")\n",
    "\n",
    "    return auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "eval_encoder(ord_enc, 'OrdinalEncoder', X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScIo7NthP75a"
   },
   "source": [
    "#### __Задание 4. One-Hot Encoding__ (0.5 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3sFuKAtLwOx"
   },
   "source": [
    "Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (в сравнении с тем, что было до кодирования). Измерьте время, потребовавшееся на кодирование категориальных признаков и обучение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4PbjLIHP75a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_enc = OneHotEncoder()\n",
    "\n",
    "eval_encoder(one_hot_enc, 'OneHotEncoder', X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p-qOs6lP75b"
   },
   "source": [
    "Как можно заметить, one-hot-кодирование может сильно увеличивать количество признаков. Это сказывается на объеме необходимой памяти, особенно, если некоторый признак имеет большое количество значений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1q3k3yaLF8Y"
   },
   "source": [
    "#### __Задание 5. Mean-target Encoding__ (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tanu5Hm5Lr7R"
   },
   "source": [
    "> Проблемы разрастания числа признаков можно избежать в другом способе кодирования категориальных признаков — mean-target encoding (для простоты будем называть это __счётчиками__). Сравним эффективность методов в рамках нашей маркетинговой задачи.\n",
    "\n",
    "> Основная идея в том, что важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше, без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве.\n",
    "\n",
    "Сравните время обучения с предыдущими экспериментами (с учетом кодирования признаков)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABXherJ3LGBj"
   },
   "source": [
    "##### __Бонус: Эффективная реализация (1 балл)__\n",
    "\n",
    "Здесь и далее реализуйте вычисление счетчиков с помощью трансформера (наследуйтесь от классов `BaseEstimator, TransformerMixin` из `sklearn.base`). Обратите внимание, что все вычисления должны быть векторизованными, трансформер не должен модифицировать передаваемую ему выборку inplace, а все необходимые статистики нужно считать только по обучающей выборке в методе `fit`. Ваш трансформер должен принимать при инициализации список из категориальных признаков и изменять только их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk8D4dDuP75b"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MeanTargetEncoder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, sigma):\n",
    "        self.global_mean = None\n",
    "        self.encoding_dicts = {}\n",
    "        self.sigma = sigma\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()\n",
    "        X = pd.concat([X, y], axis=1)\n",
    "        self.global_mean = y.mean()\n",
    "\n",
    "        for col in X.columns:\n",
    "            mean_dict = {}\n",
    "\n",
    "            for category in X[col].unique():\n",
    "                if pd.isna(category):\n",
    "                    continue\n",
    "                mean_dict[category] = X[X[col] == category]['Purchased Bike'].mean() + np.random.normal(0, self.sigma)\n",
    "            \n",
    "            self.encoding_dicts[col] = mean_dict\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            X[f'{col} Enc'] = X[col].map(self.encoding_dicts[col])\n",
    "            X.drop(columns=[col], inplace=True)\n",
    "            X[f'{col} Enc'] = X[f'{col} Enc'].fillna(self.global_mean)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target_enc = MeanTargetEncoder(sigma = 0.055)\n",
    "eval_encoder(mean_target_enc, 'MeanTargetEncoder', X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH-JPoINqJ62"
   },
   "source": [
    "_______\n",
    "\n",
    "__Методы борьбы с переобучением счетчиков__\n",
    "\n",
    "\n",
    "Отметим, что mean-target encoding признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к __переобучению__, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его __целевая метка не использовалась__.\n",
    "\n",
    "Это можно делать следующими способами:\n",
    "1. Вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени).\n",
    "2. Вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации).\n",
    "3. Внесение некоторого шума в посчитанные признаки.\n",
    "\n",
    "#### __Задание 6. Пошумим__  (0.5 балла)\n",
    "\n",
    "Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям.  При этом постарайтесь найти баланс между борьбой с переобучением и сохранением полезности признаков. Снова обучите логистическую регрессию, оцените качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target_enc = MeanTargetEncoder(0.05599)\n",
    "auc_pr_value = eval_encoder(mean_target_enc, f'MeanTargetEncoder_0.094', X_train, X_test, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiqJBxrAP75c"
   },
   "outputs": [],
   "source": [
    "# auc_pr_list = []\n",
    "# for sigma in np.linspace(0.05, 0.12, 50):\n",
    "#     mean_target_enc = MeanTargetEncoder(sigma)\n",
    "#     auc_pr_value = eval_encoder(mean_target_enc, f'MeanTargetEncoder_{sigma:.5f}', X_train, X_test, y_train)\n",
    "#     auc_pr_list.append(auc_pr_value)\n",
    "# print(max(auc_pr_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOxwE8rGLSzH"
   },
   "source": [
    "**Вопрос:** Сделайте выводы. Помогло ли добавление шума? Почему?\n",
    "\n",
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GtUtPCjP75c"
   },
   "source": [
    "##### __Бонус: другой подход__ (0.5 балла)\n",
    "\n",
    "Посчитайте корректные счётчики первым или вторым способов из описанных выше (не забудьте добавить и шум).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTargetEncoderCV(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, sigma: float = 0, cv_num: int = 5, \n",
    "                 random_state: int = 42):\n",
    "\n",
    "        self.global_mean = None\n",
    "        self.cv_encodings = {}  # Энкодинги для каждого фолда\n",
    "        self.train_encodings = {}  # Энкодинги на всем трейне для новых данных\n",
    "        self.sigma = sigma\n",
    "        self.cv_num = cv_num\n",
    "        self.random_state = random_state\n",
    "        self.columns_to_encode = []\n",
    "        self.train_idx_by_fold = []  # Индексы трейна для каждого фолда\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "\n",
    "        X = X.copy()\n",
    "        y = y.copy()\n",
    "        \n",
    "        # Сохраняем глобальное среднее\n",
    "        self.global_mean = y.mean()\n",
    "        \n",
    "        # Определяем колонки для кодирования\n",
    "        self.len_train = X.shape[0]\n",
    "        self.columns_to_encode = X.columns.tolist()\n",
    "        \n",
    "        # Инициализируем структуры\n",
    "        self.cv_encodings = {fold: {} for fold in range(self.cv_num)}\n",
    "        self.train_encodings = {}\n",
    "        self.train_idx_by_fold = []\n",
    "        \n",
    "        # Создаем KFold\n",
    "        cv = KFold(n_splits=self.cv_num, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # Сохраняем индексы для каждого фолда\n",
    "        folds_indices = list(cv.split(X, y))\n",
    "        \n",
    "        # 1. Сохраняем энкодинги для каждого фолда (для трансформации трейна)\n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(folds_indices):\n",
    "            self.train_idx_by_fold.append((train_idx, val_idx))\n",
    "            \n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            \n",
    "            for col in self.columns_to_encode:\n",
    "                # Вычисляем энкодинг на трейне фолда\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'feature': X_train_fold[col],\n",
    "                    'target': y_train_fold\n",
    "                })\n",
    "                \n",
    "                mean_by_category = temp_df.groupby('feature')['target'].mean()\n",
    "                \n",
    "                # Добавляем шум если sigma > 0\n",
    "                if self.sigma > 0:\n",
    "                    noise = np.random.normal(0, self.sigma, size=len(mean_by_category))\n",
    "                    mean_by_category = mean_by_category + noise\n",
    "                \n",
    "                # Сохраняем для этого фолда\n",
    "                self.cv_encodings[fold_idx][col] = mean_by_category.to_dict()\n",
    "        \n",
    "        # 2. Вычисляем энкодинги на всем трейне (для трансформации новых данных)\n",
    "        for col in self.columns_to_encode:\n",
    "            temp_df = pd.DataFrame({\n",
    "                'feature': X[col],\n",
    "                'target': y\n",
    "            })\n",
    "            \n",
    "            mean_by_category = temp_df.groupby('feature')['target'].mean()\n",
    "            \n",
    "            if self.sigma > 0:\n",
    "                noise = np.random.normal(0, self.sigma, size=len(mean_by_category))\n",
    "                mean_by_category = mean_by_category + noise\n",
    "            \n",
    "            self.train_encodings[col] = mean_by_category.to_dict()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = X.reset_index(drop=True)\n",
    "        for col in self.columns_to_encode:\n",
    "            X[f'{col} Enc'] = np.zeros((X.shape[0], 1))\n",
    "        \n",
    "        if X.shape[0] == self.len_train:\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(self.train_idx_by_fold):\n",
    "                for col in self.columns_to_encode:\n",
    "                    X.loc[val_idx, f'{col} Enc'] = X.loc[val_idx, col].map(\n",
    "                        self.cv_encodings[fold_idx][col]\n",
    "                    )\n",
    "            \n",
    "            for col in self.columns_to_encode:\n",
    "                X[f'{col} Enc'] = X[f'{col} Enc'].fillna(self.global_mean)\n",
    "            \n",
    "\n",
    "        else:\n",
    "            for col in self.columns_to_encode:\n",
    "                X[f'{col} Enc'] = X[col].map(self.train_encodings[col])\n",
    "            \n",
    "            for col in self.columns_to_encode:\n",
    "                X[f'{col} Enc'] = X[f'{col} Enc'].fillna(self.global_mean)\n",
    "\n",
    "        X.drop(columns=self.columns_to_encode, inplace=True)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_target_enc_cv = MeanTargetEncoderCV()\n",
    "\n",
    "# mean_target_enc_cv.fit(X_train, y_train)\n",
    "\n",
    "# X_train_mean_enc_cv = mean_target_enc_cv.transform(X_train)\n",
    "# X_test_mean_enc_cv = mean_target_enc_cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pr_list = []\n",
    "for sigma in np.linspace(0.005, 0.9, 20):\n",
    "    mean_target_enc_cv = MeanTargetEncoderCV(sigma)\n",
    "    auc_pr_value = eval_encoder(mean_target_enc_cv, f'MeanTargetEncoderCV_{sigma:.5f}', X_train, X_test, y_train)\n",
    "    auc_pr_list.append(auc_pr_value)\n",
    "print(max(auc_pr_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: не сильно помогло"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMe2b5i6P75d"
   },
   "source": [
    "#### __Задание 7. Сглаживание счетчиков__  (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} \\mathbf{1}\\{f_j(x) = f_j(x_i),\\, y_i = +1\\} + C \\cdot \\text{global-mean}}{\\sum_{i=1}^{\\ell} \\mathbf{1}\\{f_j(x) = f_j(x_i)\\} + C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gnmTaJqP75d"
   },
   "source": [
    "> Теперь ответим на следующий вопрос: что будет, если некоторая категория встречается в выборке всего несколько раз? По этой причине производится сглаживание счётчиков. Например, на практике хорошие результаты показывает использование сглаживания средним по всей выборке:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} \\mathbf{1}\\{f_j(x) = f_j(x_i),\\, y_i = +1\\} + C \\cdot \\text{global-mean}}{\\sum_{i=1}^{\\ell} \\mathbf{1}\\{f_j(x) = f_j(x_i)\\} + C}\n",
    "$$\n",
    "где $\\text{global-mean}$ — доля объектов положительного класса в выборке, $C$ — параметр, определяющий степень сглаживания (можно использовать 10 или подобрать для каждого признака свой). Идея в том, что мы \"разбавляем\" среднее значение по категории глобальным средним значением. И тем меньше, чем большее количество объектов этой категории встречается в выборке.\n",
    "\n",
    "> Вместо среднего значения целевой переменной для сглаживания можно использовать любое другое значение от 0 до 1 (этот параметр иногда называют $prior$). Можно сделать несколько признаков с разными значениями параметра. На практике в задачах бинарной классификации полезными бывают даже отрицательные значения!\n",
    "\n",
    "Добавьте сглаживание, описанное выше и повторите эксперименты. Подберите $C$, чтобы качество было лучше, чем при использовании One-Hot-Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xRMlYQlP75d"
   },
   "outputs": [],
   "source": [
    "class MeanTargetEncoderSmoothed(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, C=1.0):\n",
    "        self.global_mean = None\n",
    "        self.encoding_dicts = {}\n",
    "        self.C = C  # Параметр сглаживания\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()\n",
    "        X = pd.concat([X, y], axis=1)\n",
    "        self.global_mean = y.mean()\n",
    "\n",
    "        for col in X.columns:\n",
    "            if col == 'Purchased Bike':  # Пропускаем целевую переменную\n",
    "                continue\n",
    "                \n",
    "            mean_dict = {}\n",
    "            \n",
    "            for category in X[col].unique():\n",
    "                if pd.isna(category):\n",
    "                    continue\n",
    "                \n",
    "                # Вычисляем сглаженное значение по формуле\n",
    "                mask = X[col] == category\n",
    "                positive_count = X.loc[mask, 'Purchased Bike'].sum()  # Количество положительных примеров\n",
    "                total_count = mask.sum()  # Общее количество примеров в категории\n",
    "                \n",
    "                # Применяем формулу сглаживания\n",
    "                smoothed_value = (positive_count + self.C * self.global_mean) / (total_count + self.C)\n",
    "                mean_dict[category] = smoothed_value\n",
    "            \n",
    "            self.encoding_dicts[col] = mean_dict\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            X[f'{col} Enc'] = X[col].map(self.encoding_dicts[col])\n",
    "            X.drop(columns=[col], inplace=True)\n",
    "            X[f'{col} Enc'] = X[f'{col} Enc'].fillna(self.global_mean)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target_enc_sm = MeanTargetEncoderSmoothed()\n",
    "\n",
    "mean_target_enc_sm.fit(X_train, y_train)\n",
    "\n",
    "X_train_mean_enc_sm = mean_target_enc_sm.transform(X_train)\n",
    "X_test_mean_enc_sm = mean_target_enc_sm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pr_list = []\n",
    "for C_val in np.linspace(0.005, 1, 20):\n",
    "    auc_pr_value = eval_encoder(MeanTargetEncoderSmoothed(C=C_val), f'MeanTargetEncoderSmoothed_{C_val:.5f}', X_train, X_test, y_train)\n",
    "    auc_pr_list.append(auc_pr_value)\n",
    "print(max(auc_pr_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TksKMbr_P75d"
   },
   "source": [
    "#### **Задание 8. Числовые или категориальные?**  (0.5 балла)\n",
    "\n",
    "Теперь добавим числовые признаки к счётчикам (тем, которые дали наибольший прирост качества).\n",
    "\n",
    "\n",
    "Проверьте их на наличие выбросов и заполните пропуски средним или медианой, подумайте, что лучше в условиях наших данных\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGE4O-alP75e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfqXdaqblnZo"
   },
   "source": [
    " Сейчас для числовых признаков мы ищем линейную зависимость, что в общем случае  может быть неверной гипотезой. Тем не менее, у этих признаков есть довольно много уникальных значений (сколько?), поэтому применять к ним one-hot кодирование может оказаться излишним. Попробуйте закодировать эти признаки с помощью счетчиков. Стало ли лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia0qk__0iNCS"
   },
   "source": [
    "> __Замечание.__ Усложнение методов вычисления счётчиков не делают результаты модели гарантированно лучше. Особенно с учётом того, что логистическая регрессия не такая сложная модель, чтобы переобучаться. Поэтому вы необязательно должны были получать на каждом шаге всё лучшие и лучшие результаты (но необходимые результаты у вас должны были получиться)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mwXyUnOP75e"
   },
   "source": [
    "\n",
    "\n",
    "Как мы могли пронаблюдать, счётчики являются конкурентной альтернативой one-hot-кодированию. Опишите, какие плюсы и минусы использования счётчиков по сравнению с one-hot-кодированием вы заметили.\n",
    "\n",
    "__Ответ:__ # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oU4I7HjP75f"
   },
   "source": [
    "# Часть 3. Отбор признаков (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix, average_precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsmcHDoZNu5l"
   },
   "source": [
    "Загрузим данные [UCI Adult Dataset](https://archive.ics.uci.edu/ml/datasets/Adult). Этот набор данных содержит информацию о годовых доходах отдельных людей. В качестве признакового описания используется различная информация о человеке (образование, профессия, брачный статус и т.д.). Целевая переменная является бинарной: больше ли годовой доход 50K долларов или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hk7jX8EsNrz2"
   },
   "outputs": [],
   "source": [
    "# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XVqw4RQ5iXRC"
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "    'income'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=None, names=columns)\n",
    "df['income'] = (df['income'] != \" <=50K\").astype('int32')\n",
    "\n",
    "y = df['income'].copy()\n",
    "X = df.drop(columns=['income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKb6BsQMP75f"
   },
   "source": [
    "Важной частью процесса построения модели является отбор признаков. На практике многие признаки оказывают малое влияние на модель (при этом их расчёт занимает время) или даже негативно сказываются на качестве модели. Попробуем несколько подходов отбора признаков, оценим, как они влияют на качество модели и сколько времени занимают.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGqys4ZpiXjr"
   },
   "source": [
    "Разделите выборку на обучающую и тестовую в соотношении 3:1. Зафиксируйте `random_state=777`, также используйте `stratify=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M2TT35c_iYc-"
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,         \n",
    "    random_state=777,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,          \n",
    "    random_state=777,\n",
    "    stratify=y_temp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uAlw2X-P75f"
   },
   "source": [
    "Давайте закодируем все категориальные признаки с помощью One-hot Encoding. Сколько новых признаков мы получим?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ILg-JGugP75f"
   },
   "outputs": [],
   "source": [
    "one_hot_enc = OneHotEncoder(handle_unknown='ignore',\n",
    "                            sparse_output=False)\n",
    "\n",
    "X_train_cat = X_train.astype('object')\n",
    "X_test_cat = X_test.astype('object')\n",
    "X_val_cat = X_val.astype('object')\n",
    "\n",
    "X_train_enc = one_hot_enc.fit_transform(X_train_cat)\n",
    "X_test_enc = one_hot_enc.transform(X_test_cat)\n",
    "X_val_enc = one_hot_enc.transform(X_val_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq-XZwf3P75g"
   },
   "source": [
    "В качестве основной модели будем использовать логистическую регрессию, а целевой метрики — `AUC-PR`. Обучите модель и посчитайте качество на тестовой выборке. Давайте запомним полученное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XMH5D_6OP75g"
   },
   "outputs": [],
   "source": [
    "def eval_logreg(X_train_in, X_test_in, y_train_in, y_test_in):\n",
    "    log_reg = LogisticRegression(\n",
    "        # l1_ratio=1,\n",
    "        solver='liblinear',\n",
    "        penalty=\"l2\",\n",
    "        tol=0.0001,\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "    \n",
    "    log_reg.fit(X_train_in, y_train_in)\n",
    "    \n",
    "    y_pred_proba = log_reg.predict_proba(X_test_in)[:, 1]\n",
    "    \n",
    "    auc_pr = average_precision_score(y_test_in, y_pred_proba)\n",
    "    \n",
    "    # print(f\"AUC-PR = {auc_pr:.4f}\")\n",
    "\n",
    "    return auc_pr, log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Simplest Logistic Regression on One-Hot Encoded Data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m simple_logreg \u001b[38;5;241m=\u001b[39m eval_logreg(\u001b[43mX_train_final\u001b[49m, X_val_final, y_train, \n\u001b[1;32m      3\u001b[0m                             y_val)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_final' is not defined"
     ]
    }
   ],
   "source": [
    "# Simplest Logistic Regression on One-Hot Encoded Data\n",
    "simple_logreg = eval_logreg(X_train_final, X_val_final, y_train, \n",
    "                            y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrbIEFGUIQ6I"
   },
   "source": [
    "Допустим, мы хотим оставить только 40 лучших признаков.\n",
    "\n",
    "Заметим, что нельзя оценивать качество по тестовой выборке, иначе мы можем переобучиться, как, например, при настройке гиперпараметров. Разделите обучающую выборку на 2 части, одну из которых, используйте для валидации. Исходную тестовую выборку стоит использовать только для финальной оценки качества после процедуры фильтрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuHUvh0UwsxZ"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hymygH5YwveY"
   },
   "source": [
    "Попробуем сделать это следующими способами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QD7jIiDeP75g"
   },
   "source": [
    "#### __Задание 9. Встроенные методы (0.5 балла)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf2T9xtUP75g"
   },
   "source": [
    "Начнём с отбора признаков с помощью модели. У разных алгоритмов есть разные встроенные способы оценки вклада признаков в предсказание. Как известно, у линейной модели за это отвечают веса, а значит, их модуль можно интерпретировать как важность. Такой метод отбора называются встроенным или embedded method, так как он заложен в особенности модели.\n",
    "\n",
    "Оставьте 40 признаков с наибольшим модулем соответствующего параметра линейной модели. Обучите модели заново и оцените её качество. Замерьте скорость такого отбора признаков.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "# Get the coefficients from the simple_logreg model\n",
    "simple_logreg_coef = simple_logreg.coef_[0]\n",
    "\n",
    "# Get indices of top 40 features by absolute coefficient value\n",
    "top_40_indices = np.argsort(np.abs(simple_logreg_coef))[-40:]\n",
    "\n",
    "# Select only top 40 features from the encoded data\n",
    "X_train_top40 = X_train_enc[:, top_40_indices]\n",
    "X_test_top40 = X_test_enc[:, top_40_indices]\n",
    "\n",
    "# Measure feature selection time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# Get coefficients and select top 40 features\n",
    "simple_logreg_coef = simple_logreg.coef_[0]\n",
    "top_40_indices = np.argsort(np.abs(simple_logreg_coef))[-40:]\n",
    "X_train_top40 = X_train_enc[:, top_40_indices]\n",
    "X_test_top40 = X_test_enc[:, top_40_indices]\n",
    "\n",
    "feature_selection_time = time.time() - start_time\n",
    "print(f\"Feature selection time: {feature_selection_time:.4f} seconds\")\n",
    "\n",
    "# Train and evaluate logistic regression on top 40 features\n",
    "logreg_top40 = eval_logreg(X_train_top40, X_test_top40, y_train, y_test)\n",
    "\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCmtS99eVVrC"
   },
   "source": [
    "Изменилось ли качество? Как?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ: Качество упало в два раза, следовательно, модель недообучилась и 40 весов мало "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5y5hVyYP75h"
   },
   "source": [
    "Подумаем, что мы не учли. Мы действовали в предположении, что признаки вносят вклад равномерно, и не учитывали их масштаб. Если мы умножим один из признаков в 100 раз, то без учёта регуляризации его вес уменьшится в эти же 100 раз. А мы на основе этого отбираем признаки! Давайте сначала отмасштабируем признаки одним из способов, а только потом будем удалять признаки.\n",
    "\n",
    "Помните, что не все способы одинаково хороши, особенно в условиях наличия выбросов\n",
    "\n",
    "Кстати, в таком случае надо пересчитать качество на всех признаках (сделайте это ниже). Если вы сделали нормирование признаков в самом начале, то попробуйте отобрать признаки на неотмасштабированных данных.\n",
    "\n",
    "Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXytEuBgP75h"
   },
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "\n",
    "one_hot_enc = OneHotEncoder(handle_unknown='ignore',\n",
    "                            sparse_output=False)\n",
    "\n",
    "X_train_cat = X_train.astype('object')\n",
    "X_test_cat = X_test.astype('object')\n",
    "\n",
    "X_train_enc = one_hot_enc.fit_transform(X_train_cat)\n",
    "X_test_enc = one_hot_enc.transform(X_test_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_logreg = eval_logreg(X_train_enc, X_test_enc, y_train, y_test)\n",
    "\n",
    "# AUC-PR = 0.8198 for scaled num features + one-hot encoded data\n",
    "# AUC-PR = 0.8177 for scaled(one_hot encoded data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLZJRpxjP75h"
   },
   "source": [
    "Вопрос на засыпку: one-hot кодирование возвращает нам единичные признаки-индикаторы. Попробуйте также отскалировать их, как и обычные числовые, и снова выбрать 40 главных по вкладу признаков. Изменился ли их список? Изменится ли качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nK78Ag2P75i"
   },
   "source": [
    "#### __Задание 10. Методы фильтрации (0.5 балла)__\n",
    "\n",
    "\n",
    "Давайте отбирать признаки умнее, а именно через подсчёт некоторой функции для каждого признака. На основании значений этой функции будем оставлять наиболее важные признаки. Методы этого семейства называют фильтрующими или  filter methods.\n",
    "\n",
    "Одна из самых простых функция - корреляция между признаком и целевой переменной. Подумайте, какая взаимосвязь между корреляцией и предсказательной способностью модели, и как бы вы использовали информацию о корреляции для отбора признаков\n",
    "\n",
    "**Ответ:** # your code here\n",
    "\n",
    "Посчитайте корреляцию каждого признака с таргетом и отфильтруйте 40 признаков исходя из того, что вы описали, после чего замерьте качество и время отбора\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2E6yxKB2KBav"
   },
   "source": [
    "В качестве еще одной функция можно считать t-статистику:\n",
    "\n",
    "$$t(j) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ \\sigma^2_+ + n_- \\sigma^2_-}{n_+ + n_-}}},$$\n",
    "\n",
    "где $\\mu$, $\\sigma$, $n$ соответственно среднее, стандартное отклонение и количество объектов каждого из классов.\n",
    "\n",
    "Оставьте 40 признаков с наибольшим значением $t$, замерьте качество и скорость отбора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-IuzDptKE5J"
   },
   "outputs": [],
   "source": [
    "def select_ncols_by_t_score(X, y, n_cols=40):\n",
    "    t_scores = {}\n",
    "    DF = pd.concat([X, y], axis=1)\n",
    "    i = 0\n",
    "    for col in X.columns:\n",
    "        \n",
    "        print(i)\n",
    "        i += 1\n",
    "        mean_pos = DF[DF['income'] == 1][col].mean()\n",
    "        sigma_pos = DF[DF['income'] == 1][col].std()\n",
    "        number_pos = DF[DF['income'] == 1][col].shape[0]\n",
    "\n",
    "        mean_neg = DF[DF['income'] == 1][col].mean()\n",
    "        sigma_neg = DF[DF['income'] == 1][col].std()\n",
    "        number_neg = DF[DF['income'] == 1][col].shape[0]\n",
    "\n",
    "        t_scores[col] = abs((mean_pos - mean_neg) / np.sqrt(((sigma_pos**2 * number_pos) + (sigma_neg**2 * number_neg)) / (number_pos + number_neg)))\n",
    "    \n",
    "    sorted_t_scores = sorted(t_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    print(sorted_t_scores)\n",
    "    selected_cols = [col for col, score in sorted_t_scores[:n_cols]]\n",
    "    return selected_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_top_1000 = select_ncols_by_t_score(pd.DataFrame(X_train_enc).iloc[:,:], y_train[:], n_cols=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO63RNCLP75i"
   },
   "source": [
    "#### __Задание 11. Методы-обёртки__ (1 балл)\n",
    "\n",
    "Третий из рассматриваемых нами методов работает следующим образом: мы исключаем признаки по очереди и смотрим, как это влияет на качество. Удаляем признаки таким жадным способом, пока не окажется выполненым некоторое условие (количество признаков или ухудшение качества). Более конкретно, алгоритм выглядит так:\n",
    "\n",
    "- $k$ - число признаков, которых мы хотим оставить\n",
    "- $m$ - число признаков, которых мы выбрасываем на каждой итерации, оно же длина шага\n",
    "\n",
    "Шаг $i$:\n",
    "- $F_i$ - набор признаков (равный всему множеству признаков на i=0)\n",
    "- $M_i$ - их число, в общем случае $\\max(k, M_{i-1} - m)$\n",
    "1. Если признаков осталось ровно $k$, либо метрика стала уменьшаться более, чем на $\\epsilon$ — останавливаемся (не наш случай, но так тоже можно)\n",
    "2. Обучаем модель $a_i$ на наборе $F_i$, после чего оцениваем важность признаков (любым из способов выше или какими-нибудь ещё)\n",
    "3. Отбираем $\\min(M_i - k, m)$ наиболее бесполезных, согласно пункту 2, признаков (берем $m$, если можем, иначе оставляем вплоть до k), удаляем, переходим к следующему шагу\n",
    "\n",
    "Снова оставьте только 40 признаков и оцените качество на тестовой выборке. Подберите длину шага из каких-то соображений (каких, кстати?) и замерьте время работы метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.iloc[:, [1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ISGdzDQQP75j"
   },
   "outputs": [],
   "source": [
    "def drop_feature(X, y, X_val, y_val, k, m, best_metric, eps):\n",
    "\n",
    "    i = X.shape[1]\n",
    "    metrics_dict = {}\n",
    "    M = k + 1\n",
    "    auc_pr_i = 1\n",
    "    current_indices = np.arange(X.shape[1])\n",
    "\n",
    "    while M > k and auc_pr_i > best_metric - eps and i > 0:\n",
    "        F = X.iloc[:, current_indices]\n",
    "        F_val = X_val.iloc[:, current_indices]\n",
    "        M = F.shape[1]\n",
    "\n",
    "        auc_pr_i, model = eval_logreg(F, F_val, y, y_val)\n",
    "        metrics_dict[i] = auc_pr_i\n",
    "\n",
    "        # индексы весов в порядке убывания\n",
    "        sort_indices = np.argsort(np.abs(model.coef_))\n",
    "        \n",
    "        indices_to_remove = sort_indices[0][:m]\n",
    "        \n",
    "        # Удаляем эти признаки из current_indices\n",
    "        current_indices = np.delete(current_indices, indices_to_remove)\n",
    "\n",
    "        i -= m\n",
    "\n",
    "        if i < 1000:\n",
    "            m = 5\n",
    "\n",
    "        print(f'i = {i}     AUC_PR = {auc_pr_i}')\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.concat([\n",
    "    pd.DataFrame(X_train_enc, index=X_train.index),\n",
    "    X_train.select_dtypes(exclude='object')\n",
    "], axis=1)\n",
    "\n",
    "# For validation, keep indices aligned and fill numeric NaNs with the column mean\n",
    "X_val_final = pd.concat([\n",
    "    pd.DataFrame(X_val_enc, index=X_val.index),\n",
    "    X_val.select_dtypes(exclude='object')\n",
    "], axis=1)\n",
    "\n",
    "X_train_final.columns = X_train_final.columns.astype(str)\n",
    "X_val_final.columns = X_val_final.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 16642     AUC_PR = 0.8200255021824981\n",
      "i = 16142     AUC_PR = 0.8200255648195411\n",
      "i = 15642     AUC_PR = 0.8200250259502208\n",
      "i = 15142     AUC_PR = 0.8200212518372999\n",
      "i = 14642     AUC_PR = 0.8200236357088421\n",
      "i = 14142     AUC_PR = 0.8200263170699376\n",
      "i = 13642     AUC_PR = 0.8200308354956173\n",
      "i = 13142     AUC_PR = 0.820033287445508\n",
      "i = 12642     AUC_PR = 0.8200194767056207\n",
      "i = 12142     AUC_PR = 0.8200204332561662\n",
      "i = 11642     AUC_PR = 0.8200116998562074\n",
      "i = 11142     AUC_PR = 0.8200344454363448\n",
      "i = 10642     AUC_PR = 0.8200128858977236\n",
      "i = 10142     AUC_PR = 0.8200354451340623\n",
      "i = 9642     AUC_PR = 0.8200613387033805\n",
      "i = 9142     AUC_PR = 0.8200791031038633\n",
      "i = 8642     AUC_PR = 0.8199912024287612\n",
      "i = 8142     AUC_PR = 0.8201188041031467\n",
      "i = 7642     AUC_PR = 0.8199943201384626\n",
      "i = 7142     AUC_PR = 0.8204664833713805\n",
      "i = 6642     AUC_PR = 0.8203279735915097\n",
      "i = 6142     AUC_PR = 0.8200827634057702\n",
      "i = 5642     AUC_PR = 0.8200188582982025\n",
      "i = 5142     AUC_PR = 0.8171998811400911\n",
      "i = 4642     AUC_PR = 0.8175115142704047\n",
      "i = 4142     AUC_PR = 0.8175307300485235\n",
      "i = 3642     AUC_PR = 0.8179842479117313\n",
      "i = 3142     AUC_PR = 0.8170016937844116\n",
      "i = 2642     AUC_PR = 0.8157754755937886\n",
      "i = 2142     AUC_PR = 0.8135366710119876\n",
      "i = 1642     AUC_PR = 0.8076669608120972\n",
      "i = 1142     AUC_PR = 0.7938667812599984\n",
      "i = 642     AUC_PR = 0.784149126367654\n",
      "i = 637     AUC_PR = 0.7511342881916745\n",
      "i = 632     AUC_PR = 0.7522127384947657\n",
      "i = 627     AUC_PR = 0.7510574275415428\n",
      "i = 622     AUC_PR = 0.7406800938900532\n",
      "i = 617     AUC_PR = 0.7405531443091095\n",
      "i = 612     AUC_PR = 0.742085106361903\n",
      "i = 607     AUC_PR = 0.74056401757154\n",
      "i = 602     AUC_PR = 0.7408165297259817\n",
      "i = 597     AUC_PR = 0.7407882099802613\n",
      "i = 592     AUC_PR = 0.7389164104292874\n",
      "i = 587     AUC_PR = 0.7386226011881729\n",
      "i = 582     AUC_PR = 0.7386663312158739\n",
      "i = 577     AUC_PR = 0.7386338174557308\n",
      "i = 572     AUC_PR = 0.7386381841580392\n",
      "i = 567     AUC_PR = 0.7385465021669436\n",
      "i = 562     AUC_PR = 0.7385600128224125\n",
      "i = 557     AUC_PR = 0.7385698562152743\n",
      "i = 552     AUC_PR = 0.7402260002442328\n",
      "i = 547     AUC_PR = 0.7385701595176549\n",
      "i = 542     AUC_PR = 0.7388265102531365\n",
      "i = 537     AUC_PR = 0.7374404584425983\n",
      "i = 532     AUC_PR = 0.7376993979231672\n",
      "i = 527     AUC_PR = 0.7373703587920625\n",
      "i = 522     AUC_PR = 0.7370569322684963\n",
      "i = 517     AUC_PR = 0.7371076719268774\n",
      "i = 512     AUC_PR = 0.7371128475895343\n",
      "i = 507     AUC_PR = 0.7371771660232157\n",
      "i = 502     AUC_PR = 0.7374395659147661\n",
      "i = 497     AUC_PR = 0.7372317384496676\n",
      "i = 492     AUC_PR = 0.733858246238155\n",
      "i = 487     AUC_PR = 0.7251878018006628\n",
      "i = 482     AUC_PR = 0.7250664010656015\n",
      "i = 477     AUC_PR = 0.7250482593273774\n",
      "i = 472     AUC_PR = 0.7248245465737957\n",
      "i = 467     AUC_PR = 0.7248335720863773\n",
      "i = 462     AUC_PR = 0.7248788345196661\n",
      "i = 457     AUC_PR = 0.7248542202568705\n",
      "i = 452     AUC_PR = 0.7248586280631257\n",
      "i = 447     AUC_PR = 0.7248703003251176\n",
      "i = 442     AUC_PR = 0.7249118024121666\n",
      "i = 437     AUC_PR = 0.7240991108714829\n",
      "i = 432     AUC_PR = 0.7239462980994181\n",
      "i = 427     AUC_PR = 0.7237689715132233\n",
      "i = 422     AUC_PR = 0.7236066320972686\n",
      "i = 417     AUC_PR = 0.7235846472336898\n",
      "i = 412     AUC_PR = 0.7236239890597137\n",
      "i = 407     AUC_PR = 0.7214460405135782\n",
      "i = 402     AUC_PR = 0.7214451774428531\n",
      "i = 397     AUC_PR = 0.7214444073735138\n",
      "i = 392     AUC_PR = 0.7214747442771137\n",
      "i = 387     AUC_PR = 0.7214587394263934\n",
      "i = 382     AUC_PR = 0.721489351254639\n",
      "i = 377     AUC_PR = 0.7214632129168285\n",
      "i = 372     AUC_PR = 0.7215244726602129\n",
      "i = 367     AUC_PR = 0.7215393037433981\n",
      "i = 362     AUC_PR = 0.7215858712537725\n",
      "i = 357     AUC_PR = 0.7214007531204573\n",
      "i = 352     AUC_PR = 0.721401207066296\n",
      "i = 347     AUC_PR = 0.721252855651773\n",
      "i = 342     AUC_PR = 0.7212566983573072\n",
      "i = 337     AUC_PR = 0.7212566983573071\n",
      "i = 332     AUC_PR = 0.7212588432671304\n",
      "i = 327     AUC_PR = 0.7212583917008001\n",
      "i = 322     AUC_PR = 0.7213194940051517\n",
      "i = 317     AUC_PR = 0.7212686900645913\n",
      "i = 312     AUC_PR = 0.7212687838257299\n",
      "i = 307     AUC_PR = 0.721269410433445\n",
      "i = 302     AUC_PR = 0.7212779758661375\n",
      "i = 297     AUC_PR = 0.721290154816573\n",
      "i = 292     AUC_PR = 0.7212286293258459\n",
      "i = 287     AUC_PR = 0.7212292643451864\n",
      "i = 282     AUC_PR = 0.7213200559214469\n",
      "i = 277     AUC_PR = 0.7212752082994094\n",
      "i = 272     AUC_PR = 0.7212602006283487\n",
      "i = 267     AUC_PR = 0.7187334578951052\n",
      "i = 262     AUC_PR = 0.7174408550182427\n",
      "i = 257     AUC_PR = 0.717427807321895\n",
      "i = 252     AUC_PR = 0.7174444159020995\n",
      "i = 247     AUC_PR = 0.7174453518944471\n",
      "i = 242     AUC_PR = 0.7170663492371032\n",
      "i = 237     AUC_PR = 0.7056738790288721\n",
      "i = 232     AUC_PR = 0.7048834557158087\n",
      "i = 227     AUC_PR = 0.7048825835510056\n",
      "i = 222     AUC_PR = 0.6667795040605432\n",
      "i = 217     AUC_PR = 0.6656067601899529\n",
      "i = 212     AUC_PR = 0.665538958317321\n",
      "i = 207     AUC_PR = 0.6655032196392269\n",
      "i = 202     AUC_PR = 0.6655026845366168\n",
      "i = 197     AUC_PR = 0.664321282960184\n",
      "i = 192     AUC_PR = 0.6642566514821165\n",
      "i = 187     AUC_PR = 0.6642566848497252\n",
      "i = 182     AUC_PR = 0.6642566848497251\n",
      "i = 177     AUC_PR = 0.6641921367549387\n",
      "i = 172     AUC_PR = 0.6588577908399779\n",
      "i = 167     AUC_PR = 0.6587245619496064\n",
      "i = 162     AUC_PR = 0.6587535293582137\n",
      "i = 157     AUC_PR = 0.6566508067603557\n",
      "i = 152     AUC_PR = 0.6566202695299505\n",
      "i = 147     AUC_PR = 0.6566944214150456\n",
      "i = 142     AUC_PR = 0.6548655688140199\n",
      "i = 137     AUC_PR = 0.6542869036775938\n",
      "i = 132     AUC_PR = 0.6542869036775938\n",
      "i = 127     AUC_PR = 0.6541115028756713\n",
      "i = 122     AUC_PR = 0.6538169918834895\n",
      "i = 117     AUC_PR = 0.6534588887766543\n",
      "i = 112     AUC_PR = 0.6528968718849405\n",
      "i = 107     AUC_PR = 0.6525276232613859\n",
      "i = 102     AUC_PR = 0.6516031656054442\n",
      "i = 97     AUC_PR = 0.6500102146985911\n",
      "i = 92     AUC_PR = 0.6487415934921956\n",
      "i = 87     AUC_PR = 0.6425148002705838\n",
      "i = 82     AUC_PR = 0.641917921101863\n",
      "i = 77     AUC_PR = 0.6419649062111021\n",
      "i = 72     AUC_PR = 0.6415702365777664\n",
      "i = 67     AUC_PR = 0.6310169744754814\n",
      "i = 62     AUC_PR = 0.6299030320710255\n",
      "i = 57     AUC_PR = 0.6164518056545447\n",
      "i = 52     AUC_PR = 0.6133465517182093\n",
      "i = 47     AUC_PR = 0.6098440437727148\n",
      "i = 42     AUC_PR = 0.607344579639946\n",
      "i = 37     AUC_PR = 0.6032366626581279\n",
      "i = 32     AUC_PR = 0.5960732363179334\n"
     ]
    }
   ],
   "source": [
    "# X_train_enc.shape = (22792, 17142)\n",
    "metrics = drop_feature(pd.DataFrame(X_train_enc), y_train, pd.DataFrame(X_val_enc), y_val, 40, 500, 0.8200, 0.42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AEL4z61P75j"
   },
   "source": [
    "Стоит отметить, что с помощью такого метода можно пойти и в обратную сторону. Попробуйте _добавлять_ самые полезные признаки в выборку до тех пор, пока не наберется 40 штук. Найдется ли порог, при котором добавление следующих признаков будет только ухудшать качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzF8TzVFP75j"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj6a-BERP75j"
   },
   "source": [
    "Давайте подведём итоги по отбору признаков. Назовите преимущества и недостатки каждого из методов. Какой метод привёл к наилучшему качеству?\n",
    "\n",
    "**Ответ:** # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrR06pp7P75k"
   },
   "source": [
    "# Часть 4. Оценка экономического эффекта модели (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmgOdf7GT3uh"
   },
   "source": [
    "В данной части мы займемся тем, что от вас скорее всего потребуется на реальной работе (помимо перекладки `json`, разумеется). А именно:\n",
    "- мы соберем несколько специализированных метрик качества,\n",
    "- попытаемся настроить модель на максимизацию _прибыли_,\n",
    "- оценим, сколько вообще получится заработать на этом.\n",
    "\n",
    "Разумеется, здесь будет сделано множество упрощающих жизнь допущений, но обо всем по порядку. Если вы всё прослушали на экономике, то напомним, что выручка — это сколько денег нам принесли клиенты, а прибыль — выручка за вычетом расходов на зарплату и прочее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQkW5Xh6yip2"
   },
   "source": [
    "\n",
    "#### __Задание 12. Прогноз по доходам и расходам__ (1 балл)\n",
    "\n",
    "В этой части мы будем работать с данными [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing). Этот датасет содержит информацию о банковском телефонном маркетинге.\n",
    "\n",
    "__Объектом__ здесь является телефонный звонок потенциальному клиенту с предложением некоторой услуги (утверждается, что это краткосрочный депозит). В качестве признакового описания используются характеристики клиента (образование, брак и т.д.), данные о звонке и различные экономические индикаторы - более подробная информация представлена в файле `bank-additional-names.txt`.\n",
    "__Целевая переменная__ - ответ клиента (согласился ли он открыть депозит?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9WBqQd1aAjp"
   },
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
    "!unzip bank-additional.zip\n",
    "df = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gbw5k7lMaYT1"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmxCn_Pz3kJB"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['duration', 'y'])\n",
    "y = (df.y == 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMKgtxfwaBEQ"
   },
   "source": [
    "В этой части не нужно делить выборку - мы будем использовать кросс-валидацию.  Используйте наиболее подходящие с вашей точки зрения параметры и их значения (`shuffle`, `stratify`, число фолдов, ...). По кросс-валидации у вас получится несколько вариантов обучающей и тестовой выборки. Для удобства можно воспользоваться шаблоном ниже, который по ходу выполнения задания будет обрастать функционалом. Как обычно, это необязательно, но сохранять результаты экспериментов очень и очень желательно, в конце мы будем их сравнивать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWH-ApMjY4et"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(\n",
    "    X,\n",
    "    y,\n",
    "    n_splits=5,\n",
    "    random_state=None,\n",
    "    shuffle=False,\n",
    "    # другие аргументы, которые могут вам пригодиться дальше по пунктам\n",
    "):\n",
    "    metrics = []\n",
    "    # или любой другой фолд, посмотрите в model_selection\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        # возьмите датасет и обучите модель\n",
    "        # your code here\n",
    "\n",
    "        # посчитайте метрики, которые вам нужны и добавьте результаты с каждого фолда\n",
    "        metric_dict = {\n",
    "            # \"metric_key\": metric_value\n",
    "        }\n",
    "        metrics.append(metric_dict)\n",
    "\n",
    "    # осталось только красиво всё обернуть\n",
    "    return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIX-omTIyxtU"
   },
   "source": [
    "Выберите метрику классификации, которая вам кажется подходящей, и обучите логистическую регрессию на каждой обучающей выборке (закодируйте категориальные признаки способом, который выше вам понравился больше всех, отнормируйте числовые, гиперпараметры оставьте по умолчанию), сделайте предсказания для соответствующих тестовых выборок, выведите результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5V3f4cQryx6c"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcuHfZjfzmnt"
   },
   "source": [
    "Допустим, работники вашего колл-центра получают за один звонок клиенту 2 доллара. При согласии клиента на предлагаемые условия он принесет в банк 10 долларов. Предположим, что всем положительным прогнозам ваши сотрудники решили позвонить.\n",
    "\n",
    "В качестве бизнес-метрики в нашей задаче мы будем считать прибыль aka `profit`, соответственно лучшую модель будем выбирать исходя из этого.\n",
    "Посчитайте на всех тестовых выборках выручку и сохраните результаты для бизнес-метрики вместе с предыдущей метрикой, которую вы выбрали\n",
    "\n",
    "Ответьте на вопросы:\n",
    "- Сколько денег вы в среднем заработаете?\n",
    "- Какое получилось стандартное отклонение профита?\n",
    "- Сколько из заработанных денег придётся отдать операторам вашего колл-центра?\n",
    "- Пропорциональна ли бизнес-метрика выбранной метрике классификации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0okqAh-AzWTX"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da1x6u6wP75k"
   },
   "source": [
    "Внесем некоторую долю случайности. Пусть теперь согласный на условия клиент будет приносить не 10 долларов, а случайную величину, равномерно распределенную в интервале $[0;20)$. Проделайте все те же самые действия. Для имитации реальной ситуации **НЕ** фиксируйте `random_seed` при подсчете выручки с клиента (для разбиения на фолды разумеется оставьте). Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AKmJpRAP75k"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1g9FPExP75k"
   },
   "source": [
    "Настройте по кросс-валидации коэффициент регуляризации модели для максимизации прибыли (считайте как случайную величину выше). Удалось ли получить какой-то выигрыш? При каком коэффициенте регуляризациии прибыль максимальна? Постройте график зависимости ожидаемой прибыли от коэффициента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXx7qU5PP75l"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdptRdaIP75l"
   },
   "source": [
    "Попробуйте запустить перебор несколько раз. Находится ли каждый раз один и тот же \"лучший\" коэффициент? Присутствует ли какая-то закономерность? Какие вы можете сделать из этого выводы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inD5UMbGP75l"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0j8HubaP75l"
   },
   "source": [
    "#### __Задание 13. Ключевая метрика__ (1 балл)\n",
    "\n",
    "Выше мы уже описали примерную экономическую модель вашей задачи. Как вы считаете, что для вашего бизнеса важнее — хороший precision или recall модели? Почему?\n",
    "\n",
    "__Ответ:__ # your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LFRNnrtP75m"
   },
   "source": [
    "> Вспомним, что на самом деле логистическая регрессия предсказывает нам вероятности положительного класса для объекта. Возможно, путем настройки __порога бинаризации__ этих вероятностей мы сможем получить какой-то выигрыш?\n",
    "\n",
    "Проверьте ваши рассуждения выше с помощью настройки порога бинаризации на кросс-валидации для максимизации прибыли. Воспользуйтесь сеткой от 0 до 1 с шагом 0.01. Напомним, что снижение порога дает нам более высокий recall и более низкий precision, и наоборот. Добавьте новую ML-метрику в ваш CV-пайплайн, найдите такой порог, при котором бизнес-метрика максимальна, и проверьте, связана ли новая ML метрика с профитом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ALl1YeBP75m"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLL7uqb2P75m"
   },
   "source": [
    "Постройте график зависимости прибыли от порога бинаризации. Выделите наилучший порог\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2D3BkVsP75m"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjw2DImXXoFx"
   },
   "source": [
    "__Вопрос:__ Замечаете ли вы какую-то закономерность? Для правильного ответа на этот вопрос попробуйте запустить несколько раз и задумайтесь, почему порог получается в какой-то конкретной области?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfnHUQ7sXouL"
   },
   "source": [
    "__Ответ:__ # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tyapxyGdrSX"
   },
   "source": [
    "Наконец, чтобы точнее понять, что наша модель лучше исходной, посчитайте среднее и стандартное отклонение по фолдам бизнес-метрики для оптимизированной модели (гиперпараметры + порог) и дефолтной логистической регрессии. Проверьте, действительно ли удалось добиться значимого изменения прибыли — примените какой-либо статистический тест (например, парный t-критерий с $\\alpha=0.95$) к метрике, полученной двумя этими моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kosI-CEjeeSb"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eELf9JBWM9D5"
   },
   "source": [
    "# __Бонусная часть. Многоклассовая классификация__ (1.5 балла)\n",
    "\n",
    "Как известно, некоторые задачи не ограничиваются всего лишь двумя классами. На лекции вы проходили несколько способов обобщения линейных моделей на этот случай: One-vs-Rest и One-vs-One. Ниже мы посмотрим, в чём преимущества и недостатки обоих подходов, а так же попробуем ещё один чуть более экзотический метод\n",
    "\n",
    "#### **Задание 14. One-vs-Rest vs One-vs-One** (0.5 балла)\n",
    "\n",
    "В качестве [датасета](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention/data) здесь и ниже мы будем брать очень жизненные и актуальные данные о том, доучится студент или нет, в зависимости от курсов, возраста, гендера и прочих (не)осуждаемых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23xX_I3bO3uQ"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"thedevastator/higher-education-predictors-of-student-retention\") + \"/dataset.csv\"\n",
    "\n",
    "features = [\"Marital status\", \"Course\", \"Nacionality\", \"Gender\", \"Age at enrollment\"]\n",
    "target = \"Target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMuDGcDiO6bI"
   },
   "source": [
    "Будем смотреть только какое-то подмножество наиболее весёлых факторов. От вас по классике потребуется их преобразовать, в зависимости от того, числовые они или категориальные и **закодировать таргет чиселками!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y8NbWwPPVHZ"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8kXNmpIPYdA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=228, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4cGqq_kPfrQ"
   },
   "source": [
    "Ваш следующий шаг - посмотреть, каким образом в `sklearn` реализованы OvR и OvO, обучить таким образом логистическую регрессию с `max_iter=10000`, далее выбрать какую-то метрику (и её усреднение, его выбор тоже аргументируйте), и сравнить следующие параметры:\n",
    "- число классификаторов\n",
    "- скорость обучения\n",
    "- качество модели\n",
    "\n",
    "Также сохраните куда-нибудь предсказания вероятностей у каждой из моделей. Это можно сделать не одним способом, но возможно вам чуть с этим поможет следующий пункт\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuO6VHE1P4dA"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCxJ7e3QYsgF"
   },
   "source": [
    "Как вы объясните полученные результаты?\n",
    "\n",
    "__Ответ:__ # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "075hgy9sP7QX"
   },
   "source": [
    "#### __Задание 15. Softmax регрессия__ (1 балл)\n",
    "\n",
    "Однако любознательные машинисты могут задаться вопросом \"А зачем нам вся эта шляпа, если у сигмоиды есть обобщение на случай многоклассовой классификации?\" Если вам понравилось считать градиенты в прошлом дз, или вам нравится обучать нейросети, этот пункт для вас. Здесь мы попробуем построить одну-единственную модель, которая будет всё предсказывать, а также сравним с вариантами выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgBxUToxRPN8"
   },
   "source": [
    "Начнём с подсчёта лосса. Вспомним, что логистическая функция потерь это частный случай кросс-энтропии, её и будем пытаться оптимизировать.\n",
    "\n",
    "$$\n",
    "\\text{CE}(X, y) = -\\frac{1}{N}\\sum_i \\sum_k [y_i = k] \\log p(x_i = k)\n",
    "$$\n",
    "Вероятности в данном случае будем считать при помощи софтмакса, что есть общий случай сигмоиды\n",
    "\n",
    "$$\n",
    "p(x_i) = \\text{Softmax}(a(x_i)); \\quad\n",
    "\\text{Softmax}(x)_k = \\frac{e^{x_{k}}}{\\sum_j e^{x_{j}}} \\\\\n",
    "$$\n",
    "\n",
    "Предсказание модели на одном объекта будет делаться уже при помощи матрицы весов, посклоьку выходов несколько\n",
    "\n",
    "$$\n",
    "a(x_i) = x_i\\cdot W \\\\\n",
    "$$\n",
    "\n",
    "Ниже предлагается написать код для такой функции потерь. Если необходимо, модифицируйте шаблон по своему усмотрению (вспомогательные функции, новые аргументы, всё, что душа пожелает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYsBvtxmTK5d"
   },
   "outputs": [],
   "source": [
    "from typing import Iterable, Optional\n",
    "from torch.nn.functional import cross_entropy\n",
    "import torch\n",
    "\n",
    "def custom_ce(\n",
    "    y_pred: np.ndarray[float],\n",
    "    y_true: np.ndarray[int],\n",
    ") -> float:\n",
    "    # your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOK4eJXpSamh"
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "\n",
    "    n_objects = np.random.randint(1, 100)\n",
    "    n_classes = np.random.randint(2, 20)\n",
    "    y_pred = np.random.normal(0, 1, (n_objects, n_classes))\n",
    "    y_true = np.random.randint(low=0, high=n_classes, size=(n_objects,))\n",
    "\n",
    "    your_ce = custom_ce(y_pred, y_true) # не забудьте поправить, если меняли шаблон\n",
    "    torch_ce = cross_entropy(torch.tensor(y_pred), torch.tensor(y_true))\n",
    "    assert np.allclose(your_ce, torch_ce), \"Что-то пошло не так\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9MLDIQrT24U"
   },
   "source": [
    "Дальше самая интересная часть - нужно вывести производную этой функции потерь (на всякий случай уточним, что `torch` использовать нельзя, разве что для самопроверки). Полезные факты, которые вам могут пригодиться:\n",
    "\n",
    "- в матричном виде найти производную непросто, попробуйте сперва сделать это для одного объекта, обобщить будет полегче\n",
    "- логсофтмакс дифференцировать гораздо легче, чем просто софтмакс\n",
    "- не забывайте про правило дифференцирования сложной функции\n",
    "- поскольку веса в данном случае матрица, результат будет тоже матрица, учтите при сверке размерностей\n",
    "- если вы не придумали, как преобразовать индикаторы в векторный вид, сейчас самое время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYHes6fVVO7s"
   },
   "outputs": [],
   "source": [
    "def ce_gradient(X: np.ndarray, W: np.ndarray, y: np.ndarray) -> np.ndarray[float]:\n",
    "    # your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8KP9v4WW6UL"
   },
   "source": [
    "Дальше дело за малым. Вспомните (или узнайте), как делается градиентный спуск, и дополните класс софтмакс-регрессии ниже. Здесь разумнее использовать критерий останова по итерациям, но логрег из `sklearn` устроен немного хитрее. Если хотите добавить еще критерии останова, какие-то другие параметры, то пожалуйста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n133i8Nlc9Et"
   },
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "\n",
    "    def __init__(self, lr=1e-3, max_iter=10000):\n",
    "        self.W = None\n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # your code here\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JSpEv6oXSIX"
   },
   "source": [
    "Обучите на тех же данных, что и выше, замерьте те же три параметра, плюс сравните значения кросс-энтропии для уже трёх моделей. Сравните модели между собой и выберите фаворита в данной задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sUQDl5_Y8HB"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6xDfck0cfrr"
   },
   "source": [
    "__Ответ__: # your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACYk14eyP75n"
   },
   "source": [
    "__Бонус (0.01 балла):__ что вы кушали в день сдачи данного ДЗ на завтрак?\n",
    "\n",
    "__Ответ:__ # your answer here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xvhLtt4OP75Q",
    "RvWzOe4wP75T",
    "4VbJR0e3P75U"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

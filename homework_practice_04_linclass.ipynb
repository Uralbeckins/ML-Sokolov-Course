{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTlmjXExP75I"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 4. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kH11bAAV2SoV"
   },
   "source": [
    "### Общая информация\n",
    "Дата выдачи: 16.11.2024\n",
    "\n",
    "Мягкий дедлайн: 28.11.2024\n",
    "\n",
    "Жесткий дедлайн: 02.12.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWjJuhqS3Ucc"
   },
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- ознакомитесь с тем, что происходит \"внутри\" метода опорных векторов и логистической регрессии\n",
    "- познакомитесь с калибровкой вероятности\n",
    "- изучите методы трансформации переменных и методы отбора признаков\n",
    "- попробуете оценить экономический эффект модели\n",
    "\n",
    "----\n",
    "\n",
    "#### Самостоятельная оценка результатов\n",
    "\n",
    "Для удобства проверки, исходя из набора решенных задач, посчитайте свою максимальную оценку.\n",
    "\n",
    "**Оценка**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Or0r6z5v1Mmt"
   },
   "source": [
    "### Оценивание и штрафы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CecLXG_w3zs0"
   },
   "source": [
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMwMhTpA1MwR"
   },
   "source": [
    "### Формат сдачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5qs8FC_35h7"
   },
   "source": [
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-04-linclass-__Username__.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-04-linclass-__IvanovIvan__.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGWDDNDyP75O"
   },
   "source": [
    "# Часть 1. SVM, LR и калибровка вероятностей (2 балла + 0.5 бонус)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KyqoX1BNP75N"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "# pl.Config().set_tbl_rows(100)\n",
    "# pl.Config().set_tbl_cols(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvhLtt4OP75Q"
   },
   "source": [
    "#### __Задание 1.1  Сравнение методов__ (0.5 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZw2aOq9P75O"
   },
   "source": [
    "Сгенерируем синтетические данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqkczFrQP75P"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# фиксируем random_state для воспроизводимости результатов\n",
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=10, n_informative=5, n_redundant=5, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdPx-lQbtaRe"
   },
   "source": [
    "__Случайный классификатор__\n",
    "\n",
    "Для начала зададим самую простую модель, которая на каждом объекте выдаёт случайный ответ. По тестовой выборке вычислим AUC-ROC, AUC-PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5gcSglAOjVn-",
    "outputId": "c593c237-1319-4b1d-dbdd-5877aa42cfb1"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "random_classifier = DummyClassifier(strategy='uniform', random_state=42).fit(X_train, y_train)\n",
    "y_random = random_classifier.predict_proba(X_test)[:,1]\n",
    "y_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUhBXPre7jNi"
   },
   "source": [
    "**Вопрос:** решаем задачу бинарной классификации, но y\\_random содержит какие-то дробные числа, а не 0/1. Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpIDxyuHH1bt"
   },
   "source": [
    "**Ответ**: предсказываем вероятности вместо бинарного таргета 0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LnmZFwEYDVqx"
   },
   "source": [
    "*Ниже приведен **пример** работы* со встроенными функциями `sklearn` для отрисовки ROC и PR кривых, сохранения метрик. Пайплайн можно изменять как вам удобно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gNJLhNj7DkLx"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depict_pr_roc(y_true, y_pred, classifier_name='Some Classifier', ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "    print(classifier_name, 'metrics')\n",
    "    PrecisionRecallDisplay.from_predictions(y_true, y_pred, ax=ax[0], name=classifier_name)\n",
    "    print('AUC-PR: %.4f' % average_precision_score(y_true, y_pred))\n",
    "    ax[0].set_title(\"PRC\")\n",
    "    ax[0].set_ylim(0, 1.1)\n",
    "\n",
    "    RocCurveDisplay.from_predictions(y_true, y_pred, ax=ax[1], name=classifier_name)\n",
    "    print('AUC-ROC: %.4f' % roc_auc_score(y_true, y_pred))\n",
    "    ax[1].set_title(\"ROC\")\n",
    "    ax[1].set_ylim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "depict_pr_roc(y_test, y_random, 'Random Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "pSugCdAAEF2z",
    "outputId": "3c3cd961-bee5-4ca5-b607-6c51fc5e1b03"
   },
   "outputs": [],
   "source": [
    "# dataframe для сравнения\n",
    "# методов классификации по метрикам\n",
    "df_metrics = pd.DataFrame(\n",
    "    columns=['auc_pr', 'roc_auc_score', 'reg_const']\n",
    ")\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_random)\n",
    "# добавление очередной строки с характеристиками метода\n",
    "df_metrics.loc['Random Classifier'] = [\n",
    "      average_precision_score(y_test, y_random),\n",
    "      roc_auc_score(y_test, y_random),\n",
    "      0,\n",
    "]\n",
    "\n",
    "# по аналогии результаты следующих экспериментов можно будет собрать в табличку\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IwDobmQtW2P"
   },
   "source": [
    "__Support Vector Machine (Linear Kernel)__\n",
    "\n",
    "Обучите метод опорных векторов.\n",
    "\n",
    "Подберите параметр регуляризации `C` с точки зрения AUC-PR (можете воспользоваться кросс-валидацией или отделить валидационную выборку от обучающей).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eyjF-qc3P75Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "linear_svc = LinearSVC(C=1.0,\n",
    "                       penalty=\"l2\",\n",
    "                       tol=0.0001,\n",
    "                       random_state=42,\n",
    "                       max_iter=1000)\n",
    "\n",
    "params_linear_svc = {\n",
    "    'C': np.logspace(-9, 4, 20),\n",
    "    'tol': [1e-5, 1e-4, 1e-3, 1e-2],\n",
    "}\n",
    "\n",
    "random_search_svc = RandomizedSearchCV(\n",
    "    estimator=linear_svc,\n",
    "    param_distributions=params_linear_svc,\n",
    "    cv=5,\n",
    "    n_iter=60,\n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search_svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {random_search_svc.best_params_}')\n",
    "\n",
    "# Best parameters: {'tol': 0.001, 'C': np.float64(6.158482110660267e-05)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fapa63xlP75R"
   },
   "source": [
    "  На тестовой части:\n",
    "  - постройте ROC и PR кривые,\n",
    "  - посчитайте AUC-ROC, AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# LinearSVC doesn't output probabilities directly, so we calibrate it\n",
    "calibrated_svc = CalibratedClassifierCV(random_search_svc.best_estimator_, cv=5)\n",
    "calibrated_svc.fit(X_train, y_train)\n",
    "\n",
    "# Get probability predictions for test set\n",
    "y_svc_proba = calibrated_svc.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot ROC and PR curves\n",
    "depict_pr_roc(y_test, y_svc_proba, 'Linear SVC (Calibrated)')\n",
    "\n",
    "# Update metrics dataframe\n",
    "df_metrics.loc['Linear SVC'] = [\n",
    "    average_precision_score(y_test, y_svc_proba),\n",
    "    roc_auc_score(y_test, y_svc_proba),\n",
    "    random_search_svc.best_params_['C'],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTvgDyaFhkYz"
   },
   "source": [
    "Проанализируйте, как себя ведут обе кривые:\n",
    "- Что происходит при увеличении порога? Как бы вы это проинтерпретировали?\n",
    "- Монотонные ли кривые? Как вы это объясните?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ:\n",
    "\n",
    "-ROC всегда монотонна т.к. TRP and FPR при уменьшении порога будут монотонно расти (знаменатель постоянный у обеих), но TP и FP всегда увеличивается \n",
    "\n",
    "-Критическое различие: знаменатель precision  меняется при изменении порога"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ln5VaZE_P75S"
   },
   "source": [
    "__Logistic Regression__\n",
    "\n",
    "\n",
    "Аналогичное задание для логистической регрессии с L2 регуляризатором:\n",
    "\n",
    "\n",
    "*   подберите гиперпараметр C, используя метрику AUC-PR\n",
    "*   нарисуйте ROC, PR кривые для тестовой части\n",
    "*   выведите метрики для тестовых данных и сравните их с результатами случайного классификатора\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1TlamoBP75S"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "                            C=1.0,\n",
    "                            penalty=\"l2\",\n",
    "                            tol=0.0001,\n",
    "                            random_state=42,\n",
    "                            max_iter=1000\n",
    ")\n",
    "\n",
    "params_log_reg = {\n",
    "    'C': np.logspace(-9, 4, 20),\n",
    "    'tol': np.logspace(-8, -2, 10)\n",
    "}\n",
    "\n",
    "random_search_log_reg = RandomizedSearchCV(\n",
    "    estimator=log_reg,\n",
    "    param_distributions=params_log_reg,\n",
    "    cv=5,\n",
    "    n_iter=60,\n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search_log_reg.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {random_search_log_reg.best_params_}')\n",
    "\n",
    "# Best parameters: {'tol': np.float64(2.154822e-07), 'C': np.float64(0.00029763)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probability predictions for test set\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_log_reg_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot ROC and PR curves\n",
    "depict_pr_roc(y_test, y_log_reg_proba, 'Logistic Regression + L2')\n",
    "\n",
    "# Update metrics dataframe\n",
    "df_metrics.loc['Logistic Regression + L2'] = [\n",
    "    average_precision_score(y_test, y_log_reg_proba),\n",
    "    roc_auc_score(y_test, y_log_reg_proba),\n",
    "    random_search_log_reg.best_params_['C'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnj5PG1Rm5qX"
   },
   "source": [
    "Нарисуйте ROC, PR кривые для тестовой части для всех 3 классификаторов на одном графике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3BaXTRBnAwK"
   },
   "outputs": [],
   "source": [
    "fig, (ax_pr, ax_roc) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Random Classifier\n",
    "print('Random Classifier metrics')\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_random, ax=ax_pr, name='Random Classifier')\n",
    "print('AUC-PR: %.4f' % average_precision_score(y_test, y_random))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_random, ax=ax_roc, name='Random Classifier')\n",
    "print('AUC-ROC: %.4f' % roc_auc_score(y_test, y_random))\n",
    "\n",
    "# Linear SVC (Calibrated)\n",
    "print('\\nLinear SVC (Calibrated) metrics')\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_svc_proba, ax=ax_pr, name='Linear SVC (Calibrated)')\n",
    "print('AUC-PR: %.4f' % average_precision_score(y_test, y_svc_proba))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_svc_proba, ax=ax_roc, name='Linear SVC (Calibrated)')\n",
    "print('AUC-ROC: %.4f' % roc_auc_score(y_test, y_svc_proba))\n",
    "\n",
    "# Logistic Regression\n",
    "print('\\nLogistic Regression + L2 metrics')\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_log_reg_proba, ax=ax_pr, name='Logistic Regression + L2')\n",
    "print('AUC-PR: %.4f' % average_precision_score(y_test, y_log_reg_proba))\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, y_log_reg_proba, ax=ax_roc, name='Logistic Regression + L2')\n",
    "print('AUC-ROC: %.4f' % roc_auc_score(y_test, y_log_reg_proba))\n",
    "\n",
    "ax_pr.set_title(\"Precision-Recall Curve\")\n",
    "ax_pr.set_ylim(0, 1.1)\n",
    "ax_roc.set_title(\"ROC Curve\")\n",
    "ax_roc.set_ylim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khlorKXtr1Sy"
   },
   "source": [
    "**Вопрос:** Сравните результаты LR и SVM с точки зрения всех вычисленных критериев качества, объясните различия (если они есть).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un_w7BMZIAf2"
   },
   "source": [
    "**Ответ:** # отличий почти нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvWzOe4wP75T"
   },
   "source": [
    "#### __Задание 1.2. Визуализация в подходах SVM, LR__ (0.5 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWS1NfYwBbQ_"
   },
   "source": [
    "В названии метода опорных векторов присутствуют некоторые \"опорные векторы\". По сути, это объекты из обучающей выборки, которые задали положение разделяющей гиперплоскости.\n",
    "\n",
    "* Сгенерируйте синтетические данные с помощью `make_classification` __с 2 признаками__, обучите на нём метод опорных векторов. Не забудьте зафиксировать seed для воспроизводимости\n",
    "\n",
    "* Визуализируйте разделяющую прямую, все объекты и выделите опорные векторы. Ниже есть шаблоны, можете воспользоваться ими, либо написать своё"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qIS-aGxi-Nr0"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=10000, n_features=2, n_informative=2, n_redundant=0, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "linear_svc = SVC(kernel='linear', C=1.0, tol=0.00001, random_state=42, max_iter=1000)\n",
    "\n",
    "params_linear_svc = {\n",
    "    'C': np.logspace(-9, 4, 20),\n",
    "}\n",
    "\n",
    "random_search_svc = RandomizedSearchCV(\n",
    "    estimator=linear_svc,\n",
    "    param_distributions=params_linear_svc,\n",
    "    cv=5,\n",
    "    n_iter=60,\n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_search_svc.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: {random_search_svc.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_linear_svc = SVC(kernel='linear', **random_search_svc.best_params_, random_state=42)\n",
    "\n",
    "best_linear_svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_linear_svc.predict(X_test)\n",
    "\n",
    "df = pd.concat([pd.DataFrame(X_test, columns=['x1', 'x2']), pd.DataFrame(y_pred, columns=['y_pred'])], axis=1)\n",
    "\n",
    "print(list(best_linear_svc.coef_[0]))\n",
    "print(best_linear_svc.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = best_linear_svc.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = best_linear_svc.coef_[0]\n",
    "b = best_linear_svc.intercept_[0]\n",
    "\n",
    "# Диапазон для оси x\n",
    "xx = np.linspace(-5, 6, 100)\n",
    "yy = -(w1 * xx + b) / w2\n",
    "\n",
    "y_0 = df[df['y_pred'] == 0]\n",
    "y_1 = df[df['y_pred'] == 1]\n",
    "\n",
    "plt.figure(figsize=(14, 14))\n",
    "plt.plot(xx, yy, color='green', linewidth=2, label='Гиперплоскость')\n",
    "\n",
    "# Маржины (границы отступа): w1*x1 + w2*x2 + b = ±1\n",
    "yy_margin_plus = -(w1 * xx + b + 1) / w2\n",
    "yy_margin_minus = -(w1 * xx + b - 1) / w2\n",
    "\n",
    "plt.plot(xx, yy_margin_plus, 'r--', linewidth=2, label='Верхний margin')\n",
    "plt.plot(xx, yy_margin_minus, 'r--', linewidth=2, label='Нижний margin')\n",
    "\n",
    "plt.scatter(y_0['x1'], y_0['x2'], c='red', label='Class 0', alpha=0.7)\n",
    "plt.scatter(y_1['x1'], y_1['x2'], c='blue', label='Class 1', alpha=0.7)\n",
    "\n",
    "# НАСТОЯЩИЕ support vectors из модели LinearSVC\n",
    "# LinearSVC не предоставляет .support_vectors_ напрямую, поэтому извлекаем их\n",
    "decision_vals = best_linear_svc.decision_function(df[['x1', 'x2']])\n",
    "norm_w = np.linalg.norm([w1, w2])\n",
    "\n",
    "# Точные опорные векторы: |decision_function(x)| / ||w|| <= 1 + epsilon\n",
    "distances = np.abs(decision_vals) / norm_w\n",
    "sv_mask_true = np.abs(decision_vals) <= 1 + 1e-4  # Точные SV (|w*x + b| <= 1)\n",
    "\n",
    "# Разделяем по классам настоящие SV\n",
    "df_sv_true = df[sv_mask_true].copy()\n",
    "sv_class_0_true = df_sv_true[df_sv_true['y_pred'] == 0]\n",
    "sv_class_1_true = df_sv_true[df_sv_true['y_pred'] == 1]\n",
    "\n",
    "print(f\"True SV Class 0: {len(sv_class_0_true)}\")\n",
    "print(f\"True SV Class 1: {len(sv_class_1_true)}\")\n",
    "\n",
    "# ✅ НАСТОЯЩИЕ ОПОРНЫЕ ВЕКТОРЫ - БОЛЬШИЕ ЗВЁЗДЫ\n",
    "plt.scatter(sv_class_0_true['x1'], sv_class_0_true['x2'], \n",
    "           c='gold', s=400, marker='+', \n",
    "           edgecolors='black', linewidth=3,\n",
    "           label=f'TRUE SV Class 0 (n={len(sv_class_0_true)})', zorder=10)\n",
    "\n",
    "plt.scatter(sv_class_1_true['x1'], sv_class_1_true['x2'], \n",
    "           c='limegreen', s=400, marker='+', \n",
    "           edgecolors='black', linewidth=3,\n",
    "           label=f'TRUE SV Class 1 (n={len(sv_class_1_true)})', zorder=10)\n",
    "\n",
    "# ПСЕВДО-опорные векторы (близкие к маржину) - меньшие звёздочки для сравнения\n",
    "pseudo_sv_mask = (0.95 < distances) & (distances <= 1.1)\n",
    "df_pseudo_sv = df[pseudo_sv_mask].copy()\n",
    "pseudo_sv_0 = df_pseudo_sv[df_pseudo_sv['y_pred'] == 0]\n",
    "pseudo_sv_1 = df_pseudo_sv[df_pseudo_sv['y_pred'] == 1]\n",
    "\n",
    "plt.scatter(pseudo_sv_0['x1'], pseudo_sv_0['x2'], \n",
    "           c='darkred', s=150, marker='*', \n",
    "           edgecolors='white', linewidth=1.5,\n",
    "           label=f'Pseudo-SV Class 0 (n={len(pseudo_sv_0)})', alpha=0.8)\n",
    "\n",
    "plt.scatter(pseudo_sv_1['x1'], pseudo_sv_1['x2'], \n",
    "           c='darkblue', s=150, marker='*', \n",
    "           edgecolors='white', linewidth=1.5,\n",
    "           label=f'Pseudo-SV Class 1 (n={len(pseudo_sv_1)})', alpha=0.8)\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Проверка support_vectors_ (если доступно)\n",
    "print(\"best_linear_svc.support_vectors_:\", best_linear_svc.support_vectors_ if hasattr(best_linear_svc, 'support_vectors_') else \"Not available\")\n",
    "print(\"Количество SV по классам:\", len(sv_class_0_true), len(sv_class_1_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(X_train[:,0].min(), X_train[:,0].max(), 30)\n",
    "yy = np.linspace(X_train[:,1].min(), X_train[:,1].max(), 30)\n",
    "YY, XX = np.meshgrid(yy, xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "9jA3GbO9-wcU",
    "outputId": "bfe76c4d-7958-470d-bbb2-87c779d3fda0"
   },
   "outputs": [],
   "source": [
    "def plot_svm_2D(X, y, model,  plot_support=True):\n",
    "\n",
    "    # создали сетку\n",
    "    xx = np.linspace(X[:,0].min(), X[:,0].max(), 30)\n",
    "    yy = np.linspace(X[:,1].min(), X[:,1].max(), 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "    # Ответы модели для сетки для отрисовки разделяющей прямой\n",
    "    Z = # your code here\n",
    "\n",
    "    plt.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "\n",
    "    # Отрисовали выборку\n",
    "    plt.scatter(\n",
    "        # your code here\n",
    "    )\n",
    "\n",
    "    # Отрисовали опорные векторы\n",
    "    if plot_support:\n",
    "        plt.scatter(\n",
    "            # your code here\n",
    "            label='support vectors',\n",
    "            s=100,\n",
    "            linewidth=1,\n",
    "            edgecolor=\"blue\",\n",
    "            facecolors='none'\n",
    "        )\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_svm_2D(X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdMs4iQAIYpu"
   },
   "source": [
    "**Вопрос:** какие объекты выделяются как \"опорные\"?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dplr4chfIXnm"
   },
   "source": [
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfpVN70PP75U"
   },
   "source": [
    "В отличие от метода опорных векторов, логистическая регрессия не пытается построить разделяющую гиперплоскость с максимальным отступом, а приближает в каждой точке пространства объектов вероятность положительных ответов $p(y=+1|x)$. Попробуйте нарисовать это распределение на плоскости, не забудьте отметить на ней все объекты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "k5D2jq87f3MC",
    "outputId": "5a04f790-e90b-4f08-d25b-dd2f553d9d8d"
   },
   "outputs": [],
   "source": [
    "def plot_logreg_2D(X, y, model):\n",
    "\n",
    "    # создали сетку\n",
    "    xx = np.linspace(X[:,0].min(), X[:,0].max(), 100)\n",
    "    yy = np.linspace(X[:,1].min(), X[:,1].max(), 100)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "    # Ответы модели для сетки для отрисовки распределения\n",
    "    Z = # your code here\n",
    "    Z = Z.reshape((xx.shape[0], -1)).T\n",
    "\n",
    "    image = plt.imshow(\n",
    "        Z,\n",
    "        interpolation='nearest',\n",
    "        extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        cmap=plt.cm.PuOr_r\n",
    "    )\n",
    "\n",
    "    #Отрисовали выборку\n",
    "    plt.scatter(\n",
    "        # your code here\n",
    "        cmap=plt.cm.Paired\n",
    "    )\n",
    "\n",
    "    plt.colorbar(image)\n",
    "\n",
    "plot_logreg_2D(X, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQ-Um7-6JnAp"
   },
   "source": [
    "**Вопрос:** Как на картинке визуализирована область, где модель не уверена ($p(y=+1|x) = 0.5$)? Как это обосновать теоритечески?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAAF0HiaIh9Z"
   },
   "source": [
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VbJR0e3P75U"
   },
   "source": [
    "#### __Задание 2. Калибровка вероятностей__ (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8taLYSgBd9u"
   },
   "source": [
    "Перейдём к оценке качества выдаваемых алгоритмами вероятностей. Начнём с калибровочных кривых.\n",
    "\n",
    "Допустим, алгоритм возвращает некоторые числа от нуля до единицы. Хорошо ли они оценивают вероятность?\n",
    "\n",
    "Хорошо откалиброванный  классификатор должен выдавать значения так, чтобы среди образцов, для которых он дал значение, близкое к $\\alpha$, примерно $\\alpha * 100 \\%$ фактически принадлежали к положительному классу. (Например, если классификатор выдает 0.3 для некоторых, то 30% из них должны принадлежать классу 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRBGtMArIxMc"
   },
   "source": [
    "Для построения калибровочной криовой используем следующий алгоритм:\n",
    "\n",
    "Разобьем отрезок $[0, 1]$ на несколько маленьких отрезков одинаковой длины.\n",
    "\n",
    "Рассмотрим $i$-й отрезок с границами $[a_i, b_i]$ и предсказания $p_1, p_2, \\dots, p_k$, которые попали в него. Пусть им соответствуют истинные ответы $y_1, y_2, \\dots, y_k$. Если алгоритм выдает корректные вероятности, то среди этих истинных ответов должно быть примерно $(a_i + b_i) / 2$ единиц. Иными словами, если нарисовать кривую, у которой по оси X отложены центры отрезков, а по оси Y — доли единичных ответов этих в отрезках, то она должна оказаться диагональной.\n",
    "\n",
    "Ниже приведена функция, которая должна рисовать такие кривые. В ней допущено две ошибки — найдите и исправьте их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R75uefZuP75V"
   },
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_test, preds):\n",
    "    bin_middle_points = []\n",
    "    bin_real_ratios = []\n",
    "    n_bins = 10\n",
    "    for i in range(n_bins):\n",
    "        l = 1.0 / n_bins * i\n",
    "        r = 1.0 / n_bins * (i + 1)\n",
    "        bin_middle_points.append((l - r) / 2)\n",
    "        bin_real_ratios.append(np.min(y_test[(preds >= l) & (preds < r)] == 1))\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(bin_middle_points, bin_real_ratios)\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R13YCkxMO_R4"
   },
   "source": [
    "Сгенерируйте синтетические данные аналогично использованным в самом первом задании. Постройте калибровочные кривые на тестовой части для логистической регрессии и метода опорных векторов (не забудьте перевести его предсказания в $[0;1]$).\n",
    "\n",
    "Отрисуйте калибровочную кривую идеально откалиброванной модели (диагональ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk6pz90lQYST"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t15IAX7GPJjF"
   },
   "source": [
    "**Вопрос**: хорошо ли откалиброваны кривые для SVM, логистической регрессии? Подумайте, как это следует из вида кривой\n",
    "\n",
    "**Ответ:** # your answer here\n",
    "\n",
    "Из формальных способов в этом убедиться есть знакомый вам LogLoss, который напрямую оценивает вероятности,\n",
    "$$\\text{LogLoss} = -\\frac{1}{N}\\sum_{i} \\sum_{k \\in {0. 1}}\\log p_k[y_i = k]$$\n",
    "а так же BrierScore, который подсчитывает отклонение между получившейся вероятностью и реальным значением таргета.\n",
    "$$\\text{BrierScore} = \\frac{1}{N}\\sum_{i} (p_i - y_i)^2$$\n",
    "Посмотрите на них тоже и сделайте вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ8d-pl26rQU"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgANQZyhPHIX"
   },
   "source": [
    "Изучите распределение ответов классификаторов при помощи гистограмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAP1X3NObCXp"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.histplot(y_svc_proba, bins=50, kde=True, ax=axes[0], color='blue', alpha=0.7)\n",
    "axes[0].set_title('SVM Predicted Probabilities')\n",
    "axes[0].set_xlabel('Probability')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(y_log_reg_proba, bins=50, kde=True, ax=axes[1], color='green', alpha=0.7)\n",
    "axes[1].set_title('Logistic Regression Predicted Probabilities')\n",
    "axes[1].set_xlabel('Probability')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "sns.histplot(y_random, bins=50, kde=True, ax=axes[2], color='red', alpha=0.7)\n",
    "axes[2].set_title('Random Classifier Predicted Probabilities')\n",
    "axes[2].set_xlabel('Probability')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7ga-L4CPK_O"
   },
   "source": [
    "**Вопрос:** Чем они различаются? Чем вы можете объяснить это?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOmrLYqdPP_0"
   },
   "source": [
    "**Ответ:** \\n\\nSVM показывает бимодальное распределение с пиками вблизи 0 и 1 - модель уверена в своих предсказаниях, разделяя классы чётко.\\n\\nLogistic Regression имеет более плавное унимодальное распределение, сосредоточенное вокруг 0.5 - модель менее уверена, выдаёт предсказания ближе к порогу.\\n\\nRandom Classifier показывает равномерное распределение в диапазоне [0, 1] - случайные предсказания без уверенности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9-6ClfaP75W"
   },
   "source": [
    "Воспользуйтесь `CalibratedClassifierCV` из `sklearn` для калибровки вероятностей метода опорных векторов на обучении и постройте с его помощью  предсказания для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RR3pVlSNP75W"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnwOFuW6XyPc"
   },
   "source": [
    "**Вопрос:** Улучшились ли калибровочная кривая и качество калибровки?\n",
    "\n",
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2dpbXgoP75X"
   },
   "source": [
    "##### __Бонус: Авторское решение__ (0.5 балла)\n",
    "\n",
    "Реализуйте свою функцию для калибровки вероятностей, используя любой из известных подходов. Кратко опишите ваш подход и продемонстрируйте результаты. Ключевые слова для вдохновения: `Platt`, `Isotonic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8mtQgBJP75X"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaOVU4vJP75X"
   },
   "source": [
    "# Часть 2. Обработка категориальных переменных (4 балла + 1.5 бонус)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KQ9ywUEP75X"
   },
   "source": [
    "Как мы знаем, перекодировать категориальную переменную в список чисел (к примеру 1, 2, 3, ..., n) плохо, поскольку это бы задало на множестве ее значений некоторый порядок, не имеющий смысла.\n",
    "\n",
    "В этой части мы рассмотрим два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPsScraBP75Y"
   },
   "source": [
    "#### __Подготовка данных__\n",
    "\n",
    "*(бесценный шаг)*\n",
    "\n",
    "Разберем датасет [покупок велосипедов](https://www.kaggle.com/datasets/heeraldedhia/bike-buyers/): даны признаки покупателя, требуется предсказать, купит ли он/она велосипед\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPuDzNoCo2nk"
   },
   "source": [
    "Замените пропуски в категориальных переменных на новую категорию (`'undefined'`)\n",
    "\n",
    "Разделите признаки на 2 таблицы: категориальные и числовые признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MTr7gi1PMqv",
    "outputId": "ac75b395-3705-4a43-f024-b793d0e48c80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"heeraldedhia/bike-buyers\") +  \"/bike_buyers.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Purchased Bike'].map({'Yes': 1, 'No': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df[cat_cols].copy()\n",
    "df_num = df[num_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.drop(columns=['Purchased Bike'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.fillna('undefined', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "rGWlojJwOEjL"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_cat,\n",
    "    target,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ch0M2v8Akirw"
   },
   "source": [
    "В начале поработаем только с категориальными признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5LjHkuCP75Z"
   },
   "source": [
    "#### __Задание 3. OrdinalEncoder__  (0.5 балла)\n",
    "\n",
    "Закодируйте категориальные признаки с помощью `OrdinalEncoder`. Посчитайте качество (в этом задании будем работать c __`AUC-PR`__) при применении логистической регрессии. Замерьте время, потребовавшееся на обучение модели, с учетом кодирования признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['Encoder', 'AUC_PR', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "def eval_encoder(encoder, encoder_name, X_train_in, X_test_in, y_train_in=None):\n",
    "    start = time.time()\n",
    "    \n",
    "    if y_train_in is None:\n",
    "        X_train_enc = encoder.fit_transform(X_train_in)\n",
    "    else:\n",
    "        X_train_enc = encoder.fit_transform(X_train_in, y_train_in)\n",
    "    X_test_enc = encoder.transform(X_test_in)\n",
    "    \n",
    "    log_reg = LogisticRegression(\n",
    "        C=1.0,\n",
    "        penalty=\"l2\",\n",
    "        tol=0.0001,\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    params_log_reg = {\n",
    "        'C': np.logspace(-9, 4, 20),\n",
    "        'tol': np.logspace(-8, -2, 10)\n",
    "    }\n",
    "    kfold = KFold(5, random_state=42, shuffle=True)\n",
    "\n",
    "    random_search_log_reg = RandomizedSearchCV(\n",
    "        estimator=log_reg,\n",
    "        param_distributions=params_log_reg,\n",
    "        cv=5,\n",
    "        n_iter=60,\n",
    "        scoring='average_precision',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0  # Изменено с 1 на 0 для меньшего вывода\n",
    "    )\n",
    "\n",
    "    random_search_log_reg.fit(X_train_enc, y_train)\n",
    "    \n",
    "    # Используем best_estimator_ для предсказаний\n",
    "    y_pred_proba = random_search_log_reg.best_estimator_.predict_proba(X_test_enc)[:, 1]\n",
    "    \n",
    "    auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    end = time.time()\n",
    "    sum_time = round(end - start, 6)\n",
    "    \n",
    "    # Add results to Data Frame\n",
    "    global results\n",
    "    new_row = pd.DataFrame({\n",
    "        'Encoder': [encoder_name], \n",
    "        'AUC_PR': [auc_pr], \n",
    "        'Time': [sum_time]\n",
    "    })\n",
    "    \n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "    \n",
    "    print(f\"{encoder_name}: AUC-PR = {auc_pr:.4f}, Time = {sum_time:.4f}s\")\n",
    "\n",
    "    return auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrdinalEncoder: AUC-PR = 0.5886, Time = 0.1894s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8r/46ncjmbn5rq0s4d0hqmk4f440000gn/T/ipykernel_65532/3131977700.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.5886252772025165)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "eval_encoder(ord_enc, 'OrdinalEncoder', X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScIo7NthP75a"
   },
   "source": [
    "#### __Задание 4. One-Hot Encoding__ (0.5 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3sFuKAtLwOx"
   },
   "source": [
    "Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (в сравнении с тем, что было до кодирования). Измерьте время, потребовавшееся на кодирование категориальных признаков и обучение модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "t4PbjLIHP75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder: AUC-PR = 0.6140, Time = 0.3191s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6140415638575276)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_enc = OneHotEncoder()\n",
    "\n",
    "eval_encoder(one_hot_enc, 'OneHotEncoder', X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Encoder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AUC_PR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Time",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2595ed5c-9035-42cb-bd2a-4b43375d9359",
       "rows": [
        [
         "0",
         "OrdinalEncoder",
         "0.5886252772025165",
         "0.189353"
        ],
        [
         "1",
         "OneHotEncoder",
         "0.6140415638575276",
         "0.319132"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoder</th>\n",
       "      <th>AUC_PR</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OrdinalEncoder</td>\n",
       "      <td>0.588625</td>\n",
       "      <td>0.189353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>0.614042</td>\n",
       "      <td>0.319132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Encoder    AUC_PR      Time\n",
       "0  OrdinalEncoder  0.588625  0.189353\n",
       "1   OneHotEncoder  0.614042  0.319132"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p-qOs6lP75b"
   },
   "source": [
    "Как можно заметить, one-hot-кодирование может сильно увеличивать количество признаков. Это сказывается на объеме необходимой памяти, особенно, если некоторый признак имеет большое количество значений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1q3k3yaLF8Y"
   },
   "source": [
    "#### __Задание 5. Mean-target Encoding__ (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tanu5Hm5Lr7R"
   },
   "source": [
    "> Проблемы разрастания числа признаков можно избежать в другом способе кодирования категориальных признаков — mean-target encoding (для простоты будем называть это __счётчиками__). Сравним эффективность методов в рамках нашей маркетинговой задачи.\n",
    "\n",
    "> Основная идея в том, что важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше, без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве.\n",
    "\n",
    "Сравните время обучения с предыдущими экспериментами (с учетом кодирования признаков)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABXherJ3LGBj"
   },
   "source": [
    "##### __Бонус: Эффективная реализация (1 балл)__\n",
    "\n",
    "Здесь и далее реализуйте вычисление счетчиков с помощью трансформера (наследуйтесь от классов `BaseEstimator, TransformerMixin` из `sklearn.base`). Обратите внимание, что все вычисления должны быть векторизованными, трансформер не должен модифицировать передаваемую ему выборку inplace, а все необходимые статистики нужно считать только по обучающей выборке в методе `fit`. Ваш трансформер должен принимать при инициализации список из категориальных признаков и изменять только их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "Kk8D4dDuP75b"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MeanTargetEncoder(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, sigma):\n",
    "        self.global_mean = None\n",
    "        self.encoding_dicts = {}\n",
    "        self.sigma = sigma\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.copy()\n",
    "        X = pd.concat([X, y], axis=1)\n",
    "        self.global_mean = y.mean()\n",
    "\n",
    "        for col in X.columns:\n",
    "            mean_dict = {}\n",
    "\n",
    "            for category in X[col].unique():\n",
    "                if pd.isna(category):\n",
    "                    continue\n",
    "                mean_dict[category] = X[X[col] == category]['Purchased Bike'].mean() + np.random.normal(0, self.sigma)\n",
    "            \n",
    "            self.encoding_dicts[col] = mean_dict\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            X[f'{col} Enc'] = X[col].map(self.encoding_dicts[col])\n",
    "            X.drop(columns=[col], inplace=True)\n",
    "            X[f'{col} Enc'] = X[f'{col} Enc'].fillna(self.global_mean)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanTargetEncoder: AUC-PR = 0.6071, Time = 0.3183s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.6071460715598244)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_target_enc = MeanTargetEncoder(sigma = 0.055)\n",
    "eval_encoder(mean_target_enc, 'MeanTargetEncoder', X_train, X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Encoder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AUC_PR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Time",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "a987590e-410b-409e-8a85-ade0ddc1ed16",
       "rows": [
        [
         "0",
         "OrdinalEncoder",
         "0.5886252772025165",
         "0.189353"
        ],
        [
         "1",
         "OneHotEncoder",
         "0.6140415638575276",
         "0.319132"
        ],
        [
         "2",
         "MeanTargetEncoder",
         "0.6072896783953764",
         "0.339629"
        ],
        [
         "3",
         "MeanTargetEncoder",
         "0.6071460715598244",
         "0.318339"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoder</th>\n",
       "      <th>AUC_PR</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OrdinalEncoder</td>\n",
       "      <td>0.588625</td>\n",
       "      <td>0.189353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneHotEncoder</td>\n",
       "      <td>0.614042</td>\n",
       "      <td>0.319132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MeanTargetEncoder</td>\n",
       "      <td>0.607290</td>\n",
       "      <td>0.339629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MeanTargetEncoder</td>\n",
       "      <td>0.607146</td>\n",
       "      <td>0.318339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Encoder    AUC_PR      Time\n",
       "0     OrdinalEncoder  0.588625  0.189353\n",
       "1      OneHotEncoder  0.614042  0.319132\n",
       "2  MeanTargetEncoder  0.607290  0.339629\n",
       "3  MeanTargetEncoder  0.607146  0.318339"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH-JPoINqJ62"
   },
   "source": [
    "_______\n",
    "\n",
    "__Методы борьбы с переобучением счетчиков__\n",
    "\n",
    "\n",
    "Отметим, что mean-target encoding признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к __переобучению__, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его __целевая метка не использовалась__.\n",
    "\n",
    "Это можно делать следующими способами:\n",
    "1. Вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени).\n",
    "2. Вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации).\n",
    "3. Внесение некоторого шума в посчитанные признаки.\n",
    "\n",
    "#### __Задание 6. Пошумим__  (0.5 балла)\n",
    "\n",
    "Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям.  При этом постарайтесь найти баланс между борьбой с переобучением и сохранением полезности признаков. Снова обучите логистическую регрессию, оцените качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanTargetEncoder_0.094: AUC-PR = 0.6119, Time = 0.2591s\n"
     ]
    }
   ],
   "source": [
    "mean_target_enc = MeanTargetEncoder(0.05599)\n",
    "auc_pr_value = eval_encoder(mean_target_enc, f'MeanTargetEncoder_0.094', X_train, X_test, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiqJBxrAP75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanTargetEncoder_0.050: AUC-PR = 0.6030, Time = 2.4699s\n",
      "MeanTargetEncoder_0.050: AUC-PR = 0.5927, Time = 0.2566s\n",
      "MeanTargetEncoder_0.051: AUC-PR = 0.5796, Time = 0.2605s\n",
      "MeanTargetEncoder_0.051: AUC-PR = 0.6001, Time = 0.2577s\n",
      "MeanTargetEncoder_0.051: AUC-PR = 0.6365, Time = 0.2398s\n",
      "MeanTargetEncoder_0.052: AUC-PR = 0.6017, Time = 0.2411s\n",
      "MeanTargetEncoder_0.052: AUC-PR = 0.6137, Time = 0.2406s\n",
      "MeanTargetEncoder_0.052: AUC-PR = 0.6092, Time = 0.2471s\n",
      "MeanTargetEncoder_0.053: AUC-PR = 0.6042, Time = 0.2306s\n",
      "MeanTargetEncoder_0.053: AUC-PR = 0.6019, Time = 0.2397s\n",
      "MeanTargetEncoder_0.054: AUC-PR = 0.5895, Time = 0.2343s\n",
      "MeanTargetEncoder_0.054: AUC-PR = 0.5973, Time = 0.2558s\n",
      "MeanTargetEncoder_0.054: AUC-PR = 0.5827, Time = 0.2843s\n",
      "MeanTargetEncoder_0.055: AUC-PR = 0.5891, Time = 0.2443s\n",
      "MeanTargetEncoder_0.055: AUC-PR = 0.6406, Time = 0.2663s\n",
      "MeanTargetEncoder_0.055: AUC-PR = 0.6398, Time = 0.2356s\n",
      "MeanTargetEncoder_0.056: AUC-PR = 0.5999, Time = 0.2335s\n",
      "MeanTargetEncoder_0.056: AUC-PR = 0.6249, Time = 0.2592s\n",
      "MeanTargetEncoder_0.056: AUC-PR = 0.6130, Time = 0.2406s\n",
      "MeanTargetEncoder_0.057: AUC-PR = 0.6060, Time = 0.2333s\n",
      "MeanTargetEncoder_0.057: AUC-PR = 0.5861, Time = 0.2374s\n",
      "MeanTargetEncoder_0.057: AUC-PR = 0.5954, Time = 0.2329s\n",
      "MeanTargetEncoder_0.058: AUC-PR = 0.5612, Time = 0.2448s\n",
      "MeanTargetEncoder_0.058: AUC-PR = 0.6039, Time = 0.2602s\n",
      "MeanTargetEncoder_0.058: AUC-PR = 0.5757, Time = 0.2508s\n",
      "MeanTargetEncoder_0.059: AUC-PR = 0.6037, Time = 0.2298s\n",
      "MeanTargetEncoder_0.059: AUC-PR = 0.6269, Time = 0.2435s\n",
      "MeanTargetEncoder_0.059: AUC-PR = 0.6316, Time = 0.2322s\n",
      "MeanTargetEncoder_0.060: AUC-PR = 0.5973, Time = 0.2405s\n",
      "MeanTargetEncoder_0.060: AUC-PR = 0.6265, Time = 0.2417s\n",
      "MeanTargetEncoder_0.061: AUC-PR = 0.6415, Time = 0.2380s\n",
      "MeanTargetEncoder_0.061: AUC-PR = 0.5985, Time = 0.2381s\n",
      "MeanTargetEncoder_0.061: AUC-PR = 0.6006, Time = 0.2419s\n",
      "MeanTargetEncoder_0.062: AUC-PR = 0.5838, Time = 0.2306s\n",
      "MeanTargetEncoder_0.062: AUC-PR = 0.6379, Time = 0.2462s\n",
      "MeanTargetEncoder_0.062: AUC-PR = 0.6032, Time = 0.2350s\n",
      "MeanTargetEncoder_0.063: AUC-PR = 0.5989, Time = 0.2440s\n",
      "MeanTargetEncoder_0.063: AUC-PR = 0.5703, Time = 0.2378s\n",
      "MeanTargetEncoder_0.063: AUC-PR = 0.5883, Time = 0.2329s\n",
      "MeanTargetEncoder_0.064: AUC-PR = 0.6164, Time = 0.2463s\n",
      "MeanTargetEncoder_0.064: AUC-PR = 0.6166, Time = 0.2411s\n",
      "MeanTargetEncoder_0.064: AUC-PR = 0.6171, Time = 0.2415s\n",
      "MeanTargetEncoder_0.065: AUC-PR = 0.6171, Time = 0.2454s\n",
      "MeanTargetEncoder_0.065: AUC-PR = 0.5810, Time = 0.2386s\n",
      "MeanTargetEncoder_0.065: AUC-PR = 0.5815, Time = 0.2634s\n",
      "MeanTargetEncoder_0.066: AUC-PR = 0.6091, Time = 0.2841s\n",
      "MeanTargetEncoder_0.066: AUC-PR = 0.6022, Time = 0.2544s\n",
      "MeanTargetEncoder_0.067: AUC-PR = 0.5904, Time = 0.2455s\n",
      "MeanTargetEncoder_0.067: AUC-PR = 0.5955, Time = 0.2587s\n",
      "MeanTargetEncoder_0.067: AUC-PR = 0.5894, Time = 0.3423s\n",
      "MeanTargetEncoder_0.068: AUC-PR = 0.5794, Time = 0.2692s\n",
      "MeanTargetEncoder_0.068: AUC-PR = 0.5873, Time = 0.3221s\n",
      "MeanTargetEncoder_0.068: AUC-PR = 0.5594, Time = 0.2618s\n",
      "MeanTargetEncoder_0.069: AUC-PR = 0.6223, Time = 0.2616s\n",
      "MeanTargetEncoder_0.069: AUC-PR = 0.5904, Time = 0.3151s\n",
      "MeanTargetEncoder_0.069: AUC-PR = 0.5872, Time = 0.3111s\n",
      "MeanTargetEncoder_0.070: AUC-PR = 0.5862, Time = 0.3045s\n",
      "MeanTargetEncoder_0.070: AUC-PR = 0.5878, Time = 0.2860s\n",
      "MeanTargetEncoder_0.070: AUC-PR = 0.5894, Time = 0.2392s\n",
      "MeanTargetEncoder_0.071: AUC-PR = 0.6128, Time = 0.2613s\n",
      "MeanTargetEncoder_0.071: AUC-PR = 0.6165, Time = 0.2618s\n",
      "MeanTargetEncoder_0.071: AUC-PR = 0.6303, Time = 0.2514s\n",
      "MeanTargetEncoder_0.072: AUC-PR = 0.6325, Time = 0.2316s\n",
      "MeanTargetEncoder_0.072: AUC-PR = 0.6242, Time = 0.2410s\n",
      "MeanTargetEncoder_0.073: AUC-PR = 0.6065, Time = 0.2750s\n",
      "MeanTargetEncoder_0.073: AUC-PR = 0.5860, Time = 0.2383s\n",
      "MeanTargetEncoder_0.073: AUC-PR = 0.5733, Time = 0.2409s\n",
      "MeanTargetEncoder_0.074: AUC-PR = 0.6022, Time = 0.2325s\n",
      "MeanTargetEncoder_0.074: AUC-PR = 0.6118, Time = 0.3324s\n",
      "MeanTargetEncoder_0.074: AUC-PR = 0.6046, Time = 0.2673s\n",
      "MeanTargetEncoder_0.075: AUC-PR = 0.5818, Time = 0.2832s\n",
      "MeanTargetEncoder_0.075: AUC-PR = 0.5810, Time = 0.3610s\n",
      "MeanTargetEncoder_0.075: AUC-PR = 0.5857, Time = 0.2499s\n",
      "MeanTargetEncoder_0.076: AUC-PR = 0.6067, Time = 0.2639s\n",
      "MeanTargetEncoder_0.076: AUC-PR = 0.5767, Time = 0.2569s\n",
      "MeanTargetEncoder_0.076: AUC-PR = 0.5689, Time = 0.2405s\n",
      "MeanTargetEncoder_0.077: AUC-PR = 0.6412, Time = 0.2329s\n",
      "MeanTargetEncoder_0.077: AUC-PR = 0.5983, Time = 0.2255s\n",
      "MeanTargetEncoder_0.077: AUC-PR = 0.5752, Time = 0.2374s\n",
      "MeanTargetEncoder_0.078: AUC-PR = 0.5842, Time = 0.2460s\n",
      "MeanTargetEncoder_0.078: AUC-PR = 0.6274, Time = 0.2455s\n",
      "MeanTargetEncoder_0.078: AUC-PR = 0.6090, Time = 0.3157s\n",
      "MeanTargetEncoder_0.079: AUC-PR = 0.5655, Time = 0.2240s\n",
      "MeanTargetEncoder_0.079: AUC-PR = 0.6186, Time = 0.2253s\n",
      "MeanTargetEncoder_0.080: AUC-PR = 0.5961, Time = 0.2417s\n",
      "MeanTargetEncoder_0.080: AUC-PR = 0.6011, Time = 0.2487s\n",
      "MeanTargetEncoder_0.080: AUC-PR = 0.5910, Time = 0.2397s\n",
      "MeanTargetEncoder_0.081: AUC-PR = 0.5940, Time = 0.2427s\n",
      "MeanTargetEncoder_0.081: AUC-PR = 0.5991, Time = 0.2334s\n",
      "MeanTargetEncoder_0.081: AUC-PR = 0.5837, Time = 0.2427s\n",
      "MeanTargetEncoder_0.082: AUC-PR = 0.5894, Time = 0.2380s\n",
      "MeanTargetEncoder_0.082: AUC-PR = 0.5852, Time = 0.2350s\n",
      "MeanTargetEncoder_0.082: AUC-PR = 0.5787, Time = 0.2386s\n",
      "MeanTargetEncoder_0.083: AUC-PR = 0.5756, Time = 0.2378s\n",
      "MeanTargetEncoder_0.083: AUC-PR = 0.5934, Time = 0.2663s\n",
      "MeanTargetEncoder_0.083: AUC-PR = 0.5859, Time = 0.2612s\n",
      "MeanTargetEncoder_0.084: AUC-PR = 0.5764, Time = 0.2592s\n",
      "MeanTargetEncoder_0.084: AUC-PR = 0.5615, Time = 0.2615s\n",
      "MeanTargetEncoder_0.084: AUC-PR = 0.5650, Time = 0.2399s\n",
      "MeanTargetEncoder_0.085: AUC-PR = 0.5536, Time = 0.2302s\n",
      "MeanTargetEncoder_0.085: AUC-PR = 0.5902, Time = 0.2356s\n",
      "MeanTargetEncoder_0.086: AUC-PR = 0.5920, Time = 0.2305s\n",
      "MeanTargetEncoder_0.086: AUC-PR = 0.5742, Time = 0.2432s\n",
      "MeanTargetEncoder_0.086: AUC-PR = 0.5846, Time = 0.2390s\n",
      "MeanTargetEncoder_0.087: AUC-PR = 0.6269, Time = 0.2384s\n",
      "MeanTargetEncoder_0.087: AUC-PR = 0.5930, Time = 0.2467s\n",
      "MeanTargetEncoder_0.087: AUC-PR = 0.6312, Time = 0.2499s\n",
      "MeanTargetEncoder_0.088: AUC-PR = 0.5786, Time = 0.2687s\n",
      "MeanTargetEncoder_0.088: AUC-PR = 0.5987, Time = 0.2666s\n",
      "MeanTargetEncoder_0.088: AUC-PR = 0.5844, Time = 0.2901s\n",
      "MeanTargetEncoder_0.089: AUC-PR = 0.5879, Time = 0.2415s\n",
      "MeanTargetEncoder_0.089: AUC-PR = 0.5801, Time = 0.2426s\n",
      "MeanTargetEncoder_0.089: AUC-PR = 0.5739, Time = 0.2466s\n",
      "MeanTargetEncoder_0.090: AUC-PR = 0.6189, Time = 0.2409s\n",
      "MeanTargetEncoder_0.090: AUC-PR = 0.5799, Time = 0.2545s\n",
      "MeanTargetEncoder_0.090: AUC-PR = 0.5973, Time = 0.2500s\n",
      "MeanTargetEncoder_0.091: AUC-PR = 0.6218, Time = 0.2504s\n",
      "MeanTargetEncoder_0.091: AUC-PR = 0.5826, Time = 0.2438s\n",
      "MeanTargetEncoder_0.092: AUC-PR = 0.5761, Time = 0.2425s\n",
      "MeanTargetEncoder_0.092: AUC-PR = 0.6056, Time = 0.2199s\n",
      "MeanTargetEncoder_0.092: AUC-PR = 0.5845, Time = 0.2465s\n",
      "MeanTargetEncoder_0.093: AUC-PR = 0.5754, Time = 0.2482s\n",
      "MeanTargetEncoder_0.093: AUC-PR = 0.5917, Time = 0.2436s\n",
      "MeanTargetEncoder_0.093: AUC-PR = 0.6288, Time = 0.2316s\n",
      "MeanTargetEncoder_0.094: AUC-PR = 0.5727, Time = 0.2458s\n",
      "MeanTargetEncoder_0.094: AUC-PR = 0.5762, Time = 0.2544s\n",
      "MeanTargetEncoder_0.094: AUC-PR = 0.5836, Time = 0.2628s\n",
      "MeanTargetEncoder_0.095: AUC-PR = 0.6112, Time = 0.2583s\n",
      "MeanTargetEncoder_0.095: AUC-PR = 0.5614, Time = 0.2597s\n",
      "MeanTargetEncoder_0.095: AUC-PR = 0.5844, Time = 0.2594s\n",
      "MeanTargetEncoder_0.096: AUC-PR = 0.5770, Time = 0.2414s\n",
      "MeanTargetEncoder_0.096: AUC-PR = 0.5722, Time = 0.2453s\n",
      "MeanTargetEncoder_0.096: AUC-PR = 0.5774, Time = 0.2475s\n",
      "MeanTargetEncoder_0.097: AUC-PR = 0.5694, Time = 0.2555s\n",
      "MeanTargetEncoder_0.097: AUC-PR = 0.6023, Time = 0.2436s\n",
      "MeanTargetEncoder_0.097: AUC-PR = 0.6218, Time = 0.2378s\n",
      "MeanTargetEncoder_0.098: AUC-PR = 0.5913, Time = 0.2525s\n",
      "MeanTargetEncoder_0.098: AUC-PR = 0.6002, Time = 0.2464s\n",
      "MeanTargetEncoder_0.099: AUC-PR = 0.5852, Time = 0.2542s\n",
      "MeanTargetEncoder_0.099: AUC-PR = 0.5890, Time = 0.2373s\n",
      "MeanTargetEncoder_0.099: AUC-PR = 0.5698, Time = 0.2457s\n",
      "MeanTargetEncoder_0.100: AUC-PR = 0.5929, Time = 0.2340s\n",
      "MeanTargetEncoder_0.100: AUC-PR = 0.5734, Time = 0.2452s\n",
      "MeanTargetEncoder_0.100: AUC-PR = 0.5809, Time = 0.2330s\n",
      "MeanTargetEncoder_0.101: AUC-PR = 0.5690, Time = 0.2355s\n",
      "MeanTargetEncoder_0.101: AUC-PR = 0.5758, Time = 0.2525s\n",
      "MeanTargetEncoder_0.101: AUC-PR = 0.6102, Time = 0.2581s\n",
      "MeanTargetEncoder_0.102: AUC-PR = 0.6023, Time = 0.2577s\n",
      "MeanTargetEncoder_0.102: AUC-PR = 0.6102, Time = 0.2423s\n",
      "MeanTargetEncoder_0.102: AUC-PR = 0.5702, Time = 0.2570s\n",
      "MeanTargetEncoder_0.103: AUC-PR = 0.5955, Time = 0.2460s\n",
      "MeanTargetEncoder_0.103: AUC-PR = 0.5848, Time = 0.3596s\n",
      "MeanTargetEncoder_0.103: AUC-PR = 0.5440, Time = 0.2414s\n",
      "MeanTargetEncoder_0.104: AUC-PR = 0.5696, Time = 0.2484s\n",
      "MeanTargetEncoder_0.104: AUC-PR = 0.5375, Time = 0.2535s\n",
      "MeanTargetEncoder_0.105: AUC-PR = 0.5601, Time = 0.2525s\n",
      "MeanTargetEncoder_0.105: AUC-PR = 0.5905, Time = 0.2544s\n",
      "MeanTargetEncoder_0.105: AUC-PR = 0.5790, Time = 0.2497s\n",
      "MeanTargetEncoder_0.106: AUC-PR = 0.6284, Time = 0.2580s\n",
      "MeanTargetEncoder_0.106: AUC-PR = 0.6066, Time = 0.2516s\n",
      "MeanTargetEncoder_0.106: AUC-PR = 0.5989, Time = 0.2371s\n",
      "MeanTargetEncoder_0.107: AUC-PR = 0.5680, Time = 0.2438s\n",
      "MeanTargetEncoder_0.107: AUC-PR = 0.5678, Time = 0.2524s\n",
      "MeanTargetEncoder_0.107: AUC-PR = 0.5729, Time = 0.2508s\n",
      "MeanTargetEncoder_0.108: AUC-PR = 0.5946, Time = 0.2472s\n",
      "MeanTargetEncoder_0.108: AUC-PR = 0.5691, Time = 0.2412s\n",
      "MeanTargetEncoder_0.108: AUC-PR = 0.5784, Time = 0.2401s\n",
      "MeanTargetEncoder_0.109: AUC-PR = 0.5692, Time = 0.3178s\n",
      "MeanTargetEncoder_0.109: AUC-PR = 0.5723, Time = 0.2741s\n",
      "MeanTargetEncoder_0.109: AUC-PR = 0.6118, Time = 0.2624s\n",
      "MeanTargetEncoder_0.110: AUC-PR = 0.5685, Time = 0.2715s\n",
      "MeanTargetEncoder_0.110: AUC-PR = 0.6065, Time = 0.2766s\n",
      "MeanTargetEncoder_0.111: AUC-PR = 0.5596, Time = 0.2438s\n",
      "MeanTargetEncoder_0.111: AUC-PR = 0.6204, Time = 0.2493s\n",
      "MeanTargetEncoder_0.111: AUC-PR = 0.5716, Time = 0.2392s\n",
      "MeanTargetEncoder_0.112: AUC-PR = 0.6177, Time = 0.2551s\n",
      "MeanTargetEncoder_0.112: AUC-PR = 0.5743, Time = 0.2470s\n",
      "MeanTargetEncoder_0.112: AUC-PR = 0.5903, Time = 0.2462s\n",
      "MeanTargetEncoder_0.113: AUC-PR = 0.5578, Time = 0.2420s\n",
      "MeanTargetEncoder_0.113: AUC-PR = 0.6019, Time = 0.2496s\n",
      "MeanTargetEncoder_0.113: AUC-PR = 0.5725, Time = 0.2504s\n",
      "MeanTargetEncoder_0.114: AUC-PR = 0.6145, Time = 0.2776s\n",
      "MeanTargetEncoder_0.114: AUC-PR = 0.5643, Time = 0.2751s\n",
      "MeanTargetEncoder_0.114: AUC-PR = 0.5650, Time = 0.2480s\n",
      "MeanTargetEncoder_0.115: AUC-PR = 0.5691, Time = 0.2420s\n",
      "MeanTargetEncoder_0.115: AUC-PR = 0.5617, Time = 0.2442s\n",
      "MeanTargetEncoder_0.115: AUC-PR = 0.5715, Time = 0.2660s\n",
      "MeanTargetEncoder_0.116: AUC-PR = 0.5640, Time = 0.2387s\n",
      "MeanTargetEncoder_0.116: AUC-PR = 0.5867, Time = 0.2854s\n",
      "MeanTargetEncoder_0.116: AUC-PR = 0.6304, Time = 0.2712s\n",
      "MeanTargetEncoder_0.117: AUC-PR = 0.5553, Time = 0.2982s\n",
      "MeanTargetEncoder_0.117: AUC-PR = 0.5751, Time = 0.2716s\n",
      "MeanTargetEncoder_0.118: AUC-PR = 0.5502, Time = 0.2578s\n",
      "MeanTargetEncoder_0.118: AUC-PR = 0.5831, Time = 0.2432s\n",
      "MeanTargetEncoder_0.118: AUC-PR = 0.5976, Time = 0.2458s\n",
      "MeanTargetEncoder_0.119: AUC-PR = 0.5826, Time = 0.2501s\n",
      "MeanTargetEncoder_0.119: AUC-PR = 0.5705, Time = 0.2869s\n",
      "MeanTargetEncoder_0.119: AUC-PR = 0.6006, Time = 0.2687s\n",
      "MeanTargetEncoder_0.120: AUC-PR = 0.6144, Time = 0.2284s\n",
      "MeanTargetEncoder_0.120: AUC-PR = 0.5913, Time = 0.2317s\n",
      "0.6415456214165576\n"
     ]
    }
   ],
   "source": [
    "# auc_pr_list = []\n",
    "# for sigma in np.linspace(0.05, 0.12, 200):\n",
    "#     mean_target_enc = MeanTargetEncoder(sigma)\n",
    "#     auc_pr_value = eval_encoder(mean_target_enc, f'MeanTargetEncoder_{sigma:.5f}', X_train, X_test, y_train)\n",
    "#     auc_pr_list.append(auc_pr_value)\n",
    "# print(max(auc_pr_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOxwE8rGLSzH"
   },
   "source": [
    "**Вопрос:** Сделайте выводы. Помогло ли добавление шума? Почему?\n",
    "\n",
    "**Ответ:** # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GtUtPCjP75c"
   },
   "source": [
    "##### __Бонус: другой подход__ (0.5 балла)\n",
    "\n",
    "Посчитайте корректные счётчики первым или вторым способов из описанных выше (не забудьте добавить и шум).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjqsSTd6P75c"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MeanTargetEncoderCV(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, sigma, cv_num=5):\n",
    "        self.global_mean = None\n",
    "        self.encoding_dicts = {}\n",
    "        self.sigma = sigma\n",
    "        self.cv_num = cv_num\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        cv = KFold(n_splits=self.cv_num, shuffle=True, random_state=42)\n",
    "    \n",
    "        X = X.copy()\n",
    "        X = pd.concat([X, y], axis=1)\n",
    "\n",
    "        for train_idx, test_idx in cv.split(X, y):\n",
    "            X_train_, y_train_ = X[train_idx], y[train_idx]\n",
    "            X_test_, y_test_ = X[test_idx], y[test_idx]\n",
    "            \n",
    "\n",
    "            self.global_mean = y_train.mean()\n",
    "\n",
    "            for col in X.columns:\n",
    "                mean_dict = {}\n",
    "\n",
    "                for category in X_train_[col].unique():\n",
    "                    if pd.isna(category):\n",
    "                        continue\n",
    "                    mean_dict[category] = X[X[col] == category]['Purchased Bike'].mean() + np.random.normal(0, self.sigma)\n",
    "            \n",
    "            self.encoding_dicts[col] = mean_dict\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col in X.columns:\n",
    "            X[f'{col} Enc'] = X[col].map(self.encoding_dicts[col])\n",
    "            X.drop(columns=[col], inplace=True)\n",
    "            X[f'{col} Enc'] = X[f'{col} Enc'].fillna(self.global_mean)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMe2b5i6P75d"
   },
   "source": [
    "#### __Задание 7. Сглаживание счетчиков__  (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gnmTaJqP75d"
   },
   "source": [
    "> Теперь ответим на следующий вопрос: что будет, если некоторая категория встречается в выборке всего несколько раз? По этой причине производится сглаживание счётчиков. Например, на практике хорошие результаты показывает использование сглаживания средним по всей выборке:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)][y_i = +1] + C \\times \\text{global_mean}}{\\sum_{i=1}^{\\ell} [f_j(x) = f_j(x_i)] + C}\n",
    "$$\n",
    "где $\\text{global_mean}$ — доля объектов положительного класса в выборке, $C$ — параметр, определяющий степень сглаживания (можно использовать 10 или подобрать для каждого признака свой). Идея в том, что мы \"разбавляем\" среднее значение по категории глобальным средним значением. И тем меньше, чем большее количество объектов этой категории встречается в выборке.\n",
    "\n",
    "> Вместо среднего значения целевой переменной для сглаживания можно использовать любое другое значение от 0 до 1 (этот параметр иногда называют $prior$). Можно сделать несколько признаков с разными значениями параметра. На практике в задачах бинарной классификации полезными бывают даже отрицательные значения!\n",
    "\n",
    "Добавьте сглаживание, описанное выше и повторите эксперименты. Подберите $C$, чтобы качество было лучше, чем при использовании One-Hot-Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xRMlYQlP75d"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TksKMbr_P75d"
   },
   "source": [
    "#### **Задание 8. Числовые или категориальные?**  (0.5 балла)\n",
    "\n",
    "Теперь добавим числовые признаки к счётчикам (тем, которые дали наибольший прирост качества).\n",
    "\n",
    "\n",
    "Проверьте их на наличие выбросов и заполните пропуски средним или медианой, подумайте, что лучше в условиях наших данных\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGE4O-alP75e"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfqXdaqblnZo"
   },
   "source": [
    " Сейчас для числовых признаков мы ищем линейную зависимость, что в общем случае  может быть неверной гипотезой. Тем не менее, у этих признаков есть довольно много уникальных значений (сколько?), поэтому применять к ним one-hot кодирование может оказаться излишним. Попробуйте закодировать эти признаки с помощью счетчиков. Стало ли лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3p_jGTg-h3MG"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ia0qk__0iNCS"
   },
   "source": [
    "> __Замечание.__ Усложнение методов вычисления счётчиков не делают результаты модели гарантированно лучше. Особенно с учётом того, что логистическая регрессия не такая сложная модель, чтобы переобучаться. Поэтому вы необязательно должны были получать на каждом шаге всё лучшие и лучшие результаты (но необходимые результаты у вас должны были получиться)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mwXyUnOP75e"
   },
   "source": [
    "\n",
    "\n",
    "Как мы могли пронаблюдать, счётчики являются конкурентной альтернативой one-hot-кодированию. Опишите, какие плюсы и минусы использования счётчиков по сравнению с one-hot-кодированием вы заметили.\n",
    "\n",
    "__Ответ:__ # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oU4I7HjP75f"
   },
   "source": [
    "# Часть 3. Отбор признаков (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsmcHDoZNu5l"
   },
   "source": [
    "Загрузим данные [UCI Adult Dataset](https://archive.ics.uci.edu/ml/datasets/Adult). Этот набор данных содержит информацию о годовых доходах отдельных людей. В качестве признакового описания используется различная информация о человеке (образование, профессия, брачный статус и т.д.). Целевая переменная является бинарной: больше ли годовой доход 50K долларов или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hk7jX8EsNrz2"
   },
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVqw4RQ5iXRC"
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "    'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "    'income'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('adult.data', header=None, names=columns)\n",
    "df['income'] = (df['income'] != \" <=50K\").astype('int32')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKb6BsQMP75f"
   },
   "source": [
    "Важной частью процесса построения модели является отбор признаков. На практике многие признаки оказывают малое влияние на модель (при этом их расчёт занимает время) или даже негативно сказываются на качестве модели. Попробуем несколько подходов отбора признаков, оценим, как они влияют на качество модели и сколько времени занимают.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGqys4ZpiXjr"
   },
   "source": [
    "Разделите выборку на обучающую и тестовую в соотношении 3:1. Зафиксируйте `random_state=777`, также используйте `stratify=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2TT35c_iYc-"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uAlw2X-P75f"
   },
   "source": [
    "Давайте закодируем все категориальные признаки с помощью One-hot Encoding. Сколько новых признаков мы получим?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILg-JGugP75f"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kq-XZwf3P75g"
   },
   "source": [
    "В качестве основной модели будем использовать логистическую регрессию, а целевой метрики — `AUC-PR`. Обучите модель и посчитайте качество на тестовой выборке. Давайте запомним полученное значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMH5D_6OP75g"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrbIEFGUIQ6I"
   },
   "source": [
    "Допустим, мы хотим оставить только 40 лучших признаков.\n",
    "\n",
    "Заметим, что нельзя оценивать качество по тестовой выборке, иначе мы можем переобучиться, как, например, при настройке гиперпараметров. Разделите обучающую выборку на 2 части, одну из которых, используйте для валидации. Исходную тестовую выборку стоит использовать только для финальной оценки качества после процедуры фильтрации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuHUvh0UwsxZ"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hymygH5YwveY"
   },
   "source": [
    "Попробуем сделать это следующими способами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QD7jIiDeP75g"
   },
   "source": [
    "#### __Задание 9. Встроенные методы (0.5 балла)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf2T9xtUP75g"
   },
   "source": [
    "Начнём с отбора признаков с помощью модели. У разных алгоритмов есть разные встроенные способы оценки вклада признаков в предсказание. Как известно, у линейной модели за это отвечают веса, а значит, их модуль можно интерпретировать как важность. Такой метод отбора называются встроенным или embedded method, так как он заложен в особенности модели.\n",
    "\n",
    "Оставьте 40 признаков с наибольшим модулем соответствующего параметра линейной модели. Обучите модели заново и оцените её качество. Замерьте скорость такого отбора признаков.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqOH9EunP75g"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCmtS99eVVrC"
   },
   "source": [
    "Изменилось ли качество? Как?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5y5hVyYP75h"
   },
   "source": [
    "Подумаем, что мы не учли. Мы действовали в предположении, что признаки вносят вклад равномерно, и не учитывали их масштаб. Если мы умножим один из признаков в 100 раз, то без учёта регуляризации его вес уменьшится в эти же 100 раз. А мы на основе этого отбираем признаки! Давайте сначала отмасштабируем признаки одним из способов, а только потом будем удалять признаки.\n",
    "\n",
    "Помните, что не все способы одинаково хороши, особенно в условиях наличия выбросов\n",
    "\n",
    "Кстати, в таком случае надо пересчитать качество на всех признаках (сделайте это ниже). Если вы сделали нормирование признаков в самом начале, то попробуйте отобрать признаки на неотмасштабированных данных.\n",
    "\n",
    "Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXytEuBgP75h"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLZJRpxjP75h"
   },
   "source": [
    "Вопрос на засыпку: one-hot кодирование возвращает нам единичные признаки-индикаторы. Попробуйте также отскалировать их, как и обычные числовые, и снова выбрать 40 главных по вкладу признаков. Изменился ли их список? Изменится ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpGE8ll5P75h"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nK78Ag2P75i"
   },
   "source": [
    "#### __Задание 10. Методы фильтрации (0.5 балла)__\n",
    "\n",
    "\n",
    "Давайте отбирать признаки умнее, а именно через подсчёт некоторой функции для каждого признака. На основании значений этой функции будем оставлять наиболее важные признаки. Методы этого семейства называют фильтрующими или  filter methods.\n",
    "\n",
    "Одна из самых простых функция - корреляция между признаком и целевой переменной. Подумайте, какая взаимосвязь между корреляцией и предсказательной способностью модели, и как бы вы использовали информацию о корреляции для отбора признаков\n",
    "\n",
    "**Ответ:** # your code here\n",
    "\n",
    "Посчитайте корреляцию каждого признака с таргетом и отфильтруйте 40 признаков исходя из того, что вы описали, после чего замерьте качество и время отбора\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0snv1D-hP75i"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2E6yxKB2KBav"
   },
   "source": [
    "В качестве еще одной функция можно считать t-статистику:\n",
    "\n",
    "$$t(j) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ \\sigma^2_+ + n_- \\sigma^2_-}{n_+ + n_-}}},$$\n",
    "\n",
    "где $\\mu$, $\\sigma$, $n$ соответственно среднее, стандартное отклонение и количество объектов каждого из классов.\n",
    "\n",
    "Оставьте 40 признаков с наибольшим значением $t$, замерьте качество и скорость отбора признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-IuzDptKE5J"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO63RNCLP75i"
   },
   "source": [
    "#### __Задание 11. Методы-обёртки__ (1 балл)\n",
    "\n",
    "Третий из рассматриваемых нами методов работает следующим образом: мы исключаем признаки по очереди и смотрим, как это влияет на качество. Удаляем признаки таким жадным способом, пока не окажется выполненым некоторое условие (количество признаков или ухудшение качества). Более конкретно, алгоритм выглядит так:\n",
    "\n",
    "- $k$ - число признаков, которых мы хотим оставить\n",
    "- $m$ - число признаков, которых мы выбрасываем на каждой итерации, оно же длина шага\n",
    "\n",
    "Шаг $i$:\n",
    "- $F_i$ - набор признаков (равный всему множеству признаков на i=0)\n",
    "- $M_i$ - их число, в общем случае $\\max(k, M_{i-1} - m)$\n",
    "1. Если признаков осталось ровно $k$, либо метрика стала уменьшаться более, чем на $\\epsilon$ — останавливаемся (не наш случай, но так тоже можно)\n",
    "2. Обучаем модель $a_i$ на наборе $F_i$, после чего оцениваем важность признаков (любым из способов выше или какими-нибудь ещё)\n",
    "3. Отбираем $\\min(M_i - k, m)$ наиболее бесполезных, согласно пункту 2, признаков (берем $m$, если можем, иначе оставляем вплоть до k), удаляем, переходим к следующему шагу\n",
    "\n",
    "Снова оставьте только 40 признаков и оцените качество на тестовой выборке. Подберите длину шага из каких-то соображений (каких, кстати?) и замерьте время работы метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISGdzDQQP75j"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AEL4z61P75j"
   },
   "source": [
    "Стоит отметить, что с помощью такого метода можно пойти и в обратную сторону. Попробуйте _добавлять_ самые полезные признаки в выборку до тех пор, пока не наберется 40 штук. Найдется ли порог, при котором добавление следующих признаков будет только ухудшать качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzF8TzVFP75j"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj6a-BERP75j"
   },
   "source": [
    "Давайте подведём итоги по отбору признаков. Назовите преимущества и недостатки каждого из методов. Какой метод привёл к наилучшему качеству?\n",
    "\n",
    "**Ответ:** # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrR06pp7P75k"
   },
   "source": [
    "# Часть 4. Оценка экономического эффекта модели (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmgOdf7GT3uh"
   },
   "source": [
    "В данной части мы займемся тем, что от вас скорее всего потребуется на реальной работе (помимо перекладки `json`, разумеется). А именно:\n",
    "- мы соберем несколько специализированных метрик качества,\n",
    "- попытаемся настроить модель на максимизацию _прибыли_,\n",
    "- оценим, сколько вообще получится заработать на этом.\n",
    "\n",
    "Разумеется, здесь будет сделано множество упрощающих жизнь допущений, но обо всем по порядку. Если вы всё прослушали на экономике, то напомним, что выручка — это сколько денег нам принесли клиенты, а прибыль — выручка за вычетом расходов на зарплату и прочее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQkW5Xh6yip2"
   },
   "source": [
    "\n",
    "#### __Задание 12. Прогноз по доходам и расходам__ (1 балл)\n",
    "\n",
    "В этой части мы будем работать с данными [UCI Bank Marketing Dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing). Этот датасет содержит информацию о банковском телефонном маркетинге.\n",
    "\n",
    "__Объектом__ здесь является телефонный звонок потенциальному клиенту с предложением некоторой услуги (утверждается, что это краткосрочный депозит). В качестве признакового описания используются характеристики клиента (образование, брак и т.д.), данные о звонке и различные экономические индикаторы - более подробная информация представлена в файле `bank-additional-names.txt`.\n",
    "__Целевая переменная__ - ответ клиента (согласился ли он открыть депозит?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9WBqQd1aAjp"
   },
   "outputs": [],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\n",
    "!unzip bank-additional.zip\n",
    "df = pd.read_csv('bank-additional/bank-additional-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gbw5k7lMaYT1"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmxCn_Pz3kJB"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['duration', 'y'])\n",
    "y = (df.y == 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMKgtxfwaBEQ"
   },
   "source": [
    "В этой части не нужно делить выборку - мы будем использовать кросс-валидацию.  Используйте наиболее подходящие с вашей точки зрения параметры и их значения (`shuffle`, `stratify`, число фолдов, ...). По кросс-валидации у вас получится несколько вариантов обучающей и тестовой выборки. Для удобства можно воспользоваться шаблоном ниже, который по ходу выполнения задания будет обрастать функционалом. Как обычно, это необязательно, но сохранять результаты экспериментов очень и очень желательно, в конце мы будем их сравнивать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWH-ApMjY4et"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(\n",
    "    X,\n",
    "    y,\n",
    "    n_splits=5,\n",
    "    random_state=None,\n",
    "    shuffle=False,\n",
    "    # другие аргументы, которые могут вам пригодиться дальше по пунктам\n",
    "):\n",
    "    metrics = []\n",
    "    # или любой другой фолд, посмотрите в model_selection\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        # возьмите датасет и обучите модель\n",
    "        # your code here\n",
    "\n",
    "        # посчитайте метрики, которые вам нужны и добавьте результаты с каждого фолда\n",
    "        metric_dict = {\n",
    "            # \"metric_key\": metric_value\n",
    "        }\n",
    "        metrics.append(metric_dict)\n",
    "\n",
    "    # осталось только красиво всё обернуть\n",
    "    return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIX-omTIyxtU"
   },
   "source": [
    "Выберите метрику классификации, которая вам кажется подходящей, и обучите логистическую регрессию на каждой обучающей выборке (закодируйте категориальные признаки способом, который выше вам понравился больше всех, отнормируйте числовые, гиперпараметры оставьте по умолчанию), сделайте предсказания для соответствующих тестовых выборок, выведите результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5V3f4cQryx6c"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcuHfZjfzmnt"
   },
   "source": [
    "Допустим, работники вашего колл-центра получают за один звонок клиенту 2 доллара. При согласии клиента на предлагаемые условия он принесет в банк 10 долларов. Предположим, что всем положительным прогнозам ваши сотрудники решили позвонить.\n",
    "\n",
    "В качестве бизнес-метрики в нашей задаче мы будем считать прибыль aka `profit`, соответственно лучшую модель будем выбирать исходя из этого.\n",
    "Посчитайте на всех тестовых выборках выручку и сохраните результаты для бизнес-метрики вместе с предыдущей метрикой, которую вы выбрали\n",
    "\n",
    "Ответьте на вопросы:\n",
    "- Сколько денег вы в среднем заработаете?\n",
    "- Какое получилось стандартное отклонение профита?\n",
    "- Сколько из заработанных денег придётся отдать операторам вашего колл-центра?\n",
    "- Пропорциональна ли бизнес-метрика выбранной метрике классификации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0okqAh-AzWTX"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Da1x6u6wP75k"
   },
   "source": [
    "Внесем некоторую долю случайности. Пусть теперь согласный на условия клиент будет приносить не 10 долларов, а случайную величину, равномерно распределенную в интервале $[0;20)$. Проделайте все те же самые действия. Для имитации реальной ситуации **НЕ** фиксируйте `random_seed` при подсчете выручки с клиента (для разбиения на фолды разумеется оставьте). Что получилось?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AKmJpRAP75k"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1g9FPExP75k"
   },
   "source": [
    "Настройте по кросс-валидации коэффициент регуляризации модели для максимизации прибыли (считайте как случайную величину выше). Удалось ли получить какой-то выигрыш? При каком коэффициенте регуляризациии прибыль максимальна? Постройте график зависимости ожидаемой прибыли от коэффициента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXx7qU5PP75l"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdptRdaIP75l"
   },
   "source": [
    "Попробуйте запустить перебор несколько раз. Находится ли каждый раз один и тот же \"лучший\" коэффициент? Присутствует ли какая-то закономерность? Какие вы можете сделать из этого выводы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inD5UMbGP75l"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0j8HubaP75l"
   },
   "source": [
    "#### __Задание 13. Ключевая метрика__ (1 балл)\n",
    "\n",
    "Выше мы уже описали примерную экономическую модель вашей задачи. Как вы считаете, что для вашего бизнеса важнее — хороший precision или recall модели? Почему?\n",
    "\n",
    "__Ответ:__ # your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LFRNnrtP75m"
   },
   "source": [
    "> Вспомним, что на самом деле логистическая регрессия предсказывает нам вероятности положительного класса для объекта. Возможно, путем настройки __порога бинаризации__ этих вероятностей мы сможем получить какой-то выигрыш?\n",
    "\n",
    "Проверьте ваши рассуждения выше с помощью настройки порога бинаризации на кросс-валидации для максимизации прибыли. Воспользуйтесь сеткой от 0 до 1 с шагом 0.01. Напомним, что снижение порога дает нам более высокий recall и более низкий precision, и наоборот. Добавьте новую ML-метрику в ваш CV-пайплайн, найдите такой порог, при котором бизнес-метрика максимальна, и проверьте, связана ли новая ML метрика с профитом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ALl1YeBP75m"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLL7uqb2P75m"
   },
   "source": [
    "Постройте график зависимости прибыли от порога бинаризации. Выделите наилучший порог\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2D3BkVsP75m"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjw2DImXXoFx"
   },
   "source": [
    "__Вопрос:__ Замечаете ли вы какую-то закономерность? Для правильного ответа на этот вопрос попробуйте запустить несколько раз и задумайтесь, почему порог получается в какой-то конкретной области?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfnHUQ7sXouL"
   },
   "source": [
    "__Ответ:__ # your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tyapxyGdrSX"
   },
   "source": [
    "Наконец, чтобы точнее понять, что наша модель лучше исходной, посчитайте среднее и стандартное отклонение по фолдам бизнес-метрики для оптимизированной модели (гиперпараметры + порог) и дефолтной логистической регрессии. Проверьте, действительно ли удалось добиться значимого изменения прибыли — примените какой-либо статистический тест (например, парный t-критерий с $\\alpha=0.95$) к метрике, полученной двумя этими моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kosI-CEjeeSb"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eELf9JBWM9D5"
   },
   "source": [
    "# __Бонусная часть. Многоклассовая классификация__ (1.5 балла)\n",
    "\n",
    "Как известно, некоторые задачи не ограничиваются всего лишь двумя классами. На лекции вы проходили несколько способов обобщения линейных моделей на этот случай: One-vs-Rest и One-vs-One. Ниже мы посмотрим, в чём преимущества и недостатки обоих подходов, а так же попробуем ещё один чуть более экзотический метод\n",
    "\n",
    "#### **Задание 14. One-vs-Rest vs One-vs-One** (0.5 балла)\n",
    "\n",
    "В качестве [датасета](https://www.kaggle.com/datasets/thedevastator/higher-education-predictors-of-student-retention/data) здесь и ниже мы будем брать очень жизненные и актуальные данные о том, доучится студент или нет, в зависимости от курсов, возраста, гендера и прочих (не)осуждаемых признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23xX_I3bO3uQ"
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"thedevastator/higher-education-predictors-of-student-retention\") + \"/dataset.csv\"\n",
    "\n",
    "features = [\"Marital status\", \"Course\", \"Nacionality\", \"Gender\", \"Age at enrollment\"]\n",
    "target = \"Target\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMuDGcDiO6bI"
   },
   "source": [
    "Будем смотреть только какое-то подмножество наиболее весёлых факторов. От вас по классике потребуется их преобразовать, в зависимости от того, числовые они или категориальные и **закодировать таргет чиселками!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Y8NbWwPPVHZ"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8kXNmpIPYdA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=228, shuffle=True, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4cGqq_kPfrQ"
   },
   "source": [
    "Ваш следующий шаг - посмотреть, каким образом в `sklearn` реализованы OvR и OvO, обучить таким образом логистическую регрессию с `max_iter=10000`, далее выбрать какую-то метрику (и её усреднение, его выбор тоже аргументируйте), и сравнить следующие параметры:\n",
    "- число классификаторов\n",
    "- скорость обучения\n",
    "- качество модели\n",
    "\n",
    "Также сохраните куда-нибудь предсказания вероятностей у каждой из моделей. Это можно сделать не одним способом, но возможно вам чуть с этим поможет следующий пункт\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BuO6VHE1P4dA"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCxJ7e3QYsgF"
   },
   "source": [
    "Как вы объясните полученные результаты?\n",
    "\n",
    "__Ответ:__ # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "075hgy9sP7QX"
   },
   "source": [
    "#### __Задание 15. Softmax регрессия__ (1 балл)\n",
    "\n",
    "Однако любознательные машинисты могут задаться вопросом \"А зачем нам вся эта шляпа, если у сигмоиды есть обобщение на случай многоклассовой классификации?\" Если вам понравилось считать градиенты в прошлом дз, или вам нравится обучать нейросети, этот пункт для вас. Здесь мы попробуем построить одну-единственную модель, которая будет всё предсказывать, а также сравним с вариантами выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgBxUToxRPN8"
   },
   "source": [
    "Начнём с подсчёта лосса. Вспомним, что логистическая функция потерь это частный случай кросс-энтропии, её и будем пытаться оптимизировать.\n",
    "\n",
    "$$\n",
    "\\text{CE}(X, y) = -\\frac{1}{N}\\sum_i \\sum_k [y_i = k] \\log p(x_i = k)\n",
    "$$\n",
    "Вероятности в данном случае будем считать при помощи софтмакса, что есть общий случай сигмоиды\n",
    "\n",
    "$$\n",
    "p(x_i) = \\text{Softmax}(a(x_i)); \\quad\n",
    "\\text{Softmax}(x)_k = \\frac{e^{x_{k}}}{\\sum_j e^{x_{j}}} \\\\\n",
    "$$\n",
    "\n",
    "Предсказание модели на одном объекта будет делаться уже при помощи матрицы весов, посклоьку выходов несколько\n",
    "\n",
    "$$\n",
    "a(x_i) = x_i\\cdot W \\\\\n",
    "$$\n",
    "\n",
    "Ниже предлагается написать код для такой функции потерь. Если необходимо, модифицируйте шаблон по своему усмотрению (вспомогательные функции, новые аргументы, всё, что душа пожелает)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYsBvtxmTK5d"
   },
   "outputs": [],
   "source": [
    "from typing import Iterable, Optional\n",
    "from torch.nn.functional import cross_entropy\n",
    "import torch\n",
    "\n",
    "def custom_ce(\n",
    "    y_pred: np.ndarray[float],\n",
    "    y_true: np.ndarray[int],\n",
    ") -> float:\n",
    "    # your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOK4eJXpSamh"
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "\n",
    "    n_objects = np.random.randint(1, 100)\n",
    "    n_classes = np.random.randint(2, 20)\n",
    "    y_pred = np.random.normal(0, 1, (n_objects, n_classes))\n",
    "    y_true = np.random.randint(low=0, high=n_classes, size=(n_objects,))\n",
    "\n",
    "    your_ce = custom_ce(y_pred, y_true) # не забудьте поправить, если меняли шаблон\n",
    "    torch_ce = cross_entropy(torch.tensor(y_pred), torch.tensor(y_true))\n",
    "    assert np.allclose(your_ce, torch_ce), \"Что-то пошло не так\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9MLDIQrT24U"
   },
   "source": [
    "Дальше самая интересная часть - нужно вывести производную этой функции потерь (на всякий случай уточним, что `torch` использовать нельзя, разве что для самопроверки). Полезные факты, которые вам могут пригодиться:\n",
    "\n",
    "- в матричном виде найти производную непросто, попробуйте сперва сделать это для одного объекта, обобщить будет полегче\n",
    "- логсофтмакс дифференцировать гораздо легче, чем просто софтмакс\n",
    "- не забывайте про правило дифференцирования сложной функции\n",
    "- поскольку веса в данном случае матрица, результат будет тоже матрица, учтите при сверке размерностей\n",
    "- если вы не придумали, как преобразовать индикаторы в векторный вид, сейчас самое время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYHes6fVVO7s"
   },
   "outputs": [],
   "source": [
    "def ce_gradient(X: np.ndarray, W: np.ndarray, y: np.ndarray) -> np.ndarray[float]:\n",
    "    # your code here\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8KP9v4WW6UL"
   },
   "source": [
    "Дальше дело за малым. Вспомните (или узнайте), как делается градиентный спуск, и дополните класс софтмакс-регрессии ниже. Здесь разумнее использовать критерий останова по итерациям, но логрег из `sklearn` устроен немного хитрее. Если хотите добавить еще критерии останова, какие-то другие параметры, то пожалуйста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n133i8Nlc9Et"
   },
   "outputs": [],
   "source": [
    "class SoftmaxRegression:\n",
    "\n",
    "    def __init__(self, lr=1e-3, max_iter=10000):\n",
    "        self.W = None\n",
    "        self.max_iter = max_iter\n",
    "        self.lr = lr\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # your code here\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JSpEv6oXSIX"
   },
   "source": [
    "Обучите на тех же данных, что и выше, замерьте те же три параметра, плюс сравните значения кросс-энтропии для уже трёх моделей. Сравните модели между собой и выберите фаворита в данной задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sUQDl5_Y8HB"
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6xDfck0cfrr"
   },
   "source": [
    "__Ответ__: # your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACYk14eyP75n"
   },
   "source": [
    "__Бонус (0.01 балла):__ что вы кушали в день сдачи данного ДЗ на завтрак?\n",
    "\n",
    "__Ответ:__ # your answer here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xvhLtt4OP75Q",
    "RvWzOe4wP75T",
    "4VbJR0e3P75U"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
